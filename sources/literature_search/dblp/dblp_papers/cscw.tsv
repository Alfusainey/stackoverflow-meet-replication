How People Initiate and Respond to Discussions Around Online Community Norms: A Preliminary Analysis on Meta Stack Overflow Discussions.	Jingchao Fang, Jia-Wei Liang, Hao-Chuan Wang	cscw2023c	Supporting norms-related discussions can aid people in understanding and abiding by ambiguous norms in large-scale online communities. Yet, how social and linguistic factors, such as the identities of interlocutors and the language framing of posts, can influence discussions around norms, is underexplored. In this work, we performed a preliminary analysis based on a dataset containing 123 question threads on Meta Stack Overflow, a site for discussions of the workings and policies of Stack Overflow, to understand how people initiate and respond to norms-related discussions. Results revealed that question posts with different levels of personal relatedness and question specificity have significantly different sentiments, and they also draw comments with diverged sentiments. We present implications and directions of future work based on our findings.
Exploring Distributed Synthesis: In-Progress Findings from Guided Tours of Scholarly Knowledge Synthesis Work Practices with A Distributed Lens.	Siyi Zhu, Joel Chan	cscw2023c	Synthesis — the construction of a new conceptual whole that advances understanding — is critical for research progress. Its current practice is also extremely laborious and costly. In this paper, we explore what fresh ideas CSCW might have to offer for making effective synthesis less painful and more commonplace. In particular, we draw on CSCW ideas around distributed sensemaking and integrated crowdsourcing to explore the idea of distributed synthesis: systems for sharing and reusing intermediate synthesis materials such as annotations and notes to kickstart and accelerate the synthesis process. We report in-progress findings from our analysis of in-depth guided tours of scholarly synthesis work practices, to bridge the gap between distributed sensemaking and integrated crowdsourcing (which has not yet been studied in the setting of scholarly synthesis) and scholarly synthesis workflows (which have not yet been analyzed from a distributed lens).
Investigating Users' Inclination of Leveraging Mobile Crowdsourcing to Obtain Verifying vs. Supplemental Information when Facing Inconsistent Smat-city Sensor Information.	You-Hsuan Chiang, Je-Wei Hsu, Chung-En Liu, Tzu-Yu Huang, Hsin-Lun Chiu, Yung-Ju Chang	cscw2023c	Smart cities leverage sensor technology to monitor urban spaces in real-time. Still, discrepancies in sensor data can lead to uncertainty about city conditions. Mobile crowdsourcing, where on-site individuals offer real-time details, is a potential solution. Yet it is unclear whether users would prefer to utilizing the mobile crowd on site to verify sensor data or to provide supplementary explanations for inconsistent sensor data. We conducted an online experiment involving 100 participants to explore this question. Our results revealed a negative correlation between perceived plausibility of sensor information and inclination to use mobile crowdsourcing for obtaining information. However, only around 80% of participants relied on crowdsourcing when they felt the sensor information as implausible. Interestingly, even when participants believed the sensor data to be plausible, they sought to use crowdsourcing for further details half of the time. We also found that participants leaned more towards using the crowd for explanations (48% and 49% of instances) rather than seeking verification when encountering perceived implausible sensor information (38% and 32% of instances).
CAMPUS: A University Crowdsourcing Platform for Reporting Facility, Status Update, and Problem Area Information.	Chih-Chi Chung, Yen-Chun Lin, Yu-Cheng Wang, Tze-Yu Chen, Chia-Yu Chen, Xinye Jiang, Fang-Yu Lin, Yu-Hao Weng, Yung-Ju Chang	cscw2022c	This paper presents CAMPUS, a crowdsourcing platform that enables its users to report and view information about a university’s facilities, real-time status, and problem areas via a mobile web app. The results of our preliminary evaluation indicate that this platform had the potential to inform them about its focal topics, and that they would be motivated to use it if it were deployed on a larger scale. However, the study also highlighted the challenge of dealing with users’ mutually redundant reports. Nevertheless, CAMPUS exhibits a strong potential for enabling individuals on a campus to collaboratively inform each other about campus-related information; and our future work will show how individuals on campus leverage this system on a daily basis.
Action-a-Bot: Exploring Human-Chatbot Conversations for Actionable Instruction Giving and Following.	Qingxiaoyang Zhu, Yi-Chieh Lee, Hao-Chuan Wang	cscw2022c	Conversation serves as one critical mechanism for knowledge-sharing and instruction-giving in collaborative work. Conversation allows people to take turns to make contributions, plan joint actions, align shared understanding of work status and resolve action failure. However, when such collaboration involves non-human AI actors like chatbots, there is a lack of understanding of how human participants may respond to the chatbot’s prompts and guidance, and whether the interaction can similarly improve the actionability of instructions given to people. In this study, we prototyped a chatbot system, ActionaBot for providing task instructions to novice workers, and conducted an initial study to explore its effects on procedural instruction giving and following. Our results indicate that, novices although might perceive instructions to be inactionable due to prior experience and how instructions were authored, they were able to follow conversational guidance and willing to adapt to the chatbot through turn-taking to calibrate working states back-and-forth. Besides, users’ awareness of the work status increased with the conversational prompts from the chatbot.
Bridging Actionability Gap in Online How-To Instruction-Following Through Human-Chatbot Interaction.	Qingxiaoyang Zhu	cscw2022c	People frequently come across unfamiliar tasks to complete in daily and professional life. A common strategy to accomplish such tasks is to refer to online How-To tutorials (e.g., wikiHow pages) and follow the instructions step-by-step. However, such archived tutorials are not always actionable, since the sequence of actions is pre-defined and could result in a discrepancy between what was shared and what people need in operational situations. Differing from regular conversational instruction-giving, where people are able to communicate instructions adaptively based on the ongoing working status, archived procedures lack such flexibility. As such, people may face actionability issues in which they may have difficulties navigating the instruction, making decisions on what to do, and solving problems. My dissertation explores system designs using chatbots to accompany novice users to improve the situational actionability and social acceptability of online tutorials for non-expert users. I present ActionaBot, an experimental platform for exploring human-chatbot collaborative instruction giving to augment online tutorials. By participating in the Doctoral Consortium, I am eager to receive feedback from experienced CSCW researchers to inform my research direction. In the long run, I aim to contribute a better understanding of how people and the chatbot may collaborate to enable actionable knowledge sharing and transfer at a large scale.
Bridging from Crisis to Everyday Life - An Analysis of User Reviews of the Warning App NINA and the COVID-19 Regulation Apps CoroBuddy and DarfIchDas.	Jasmin Haunschild, Christian Reuter	cscw2021c	During a dynamic and protracted crisis such as the COVID-19 pandemic, citizens are continuously challenged with making decisions under uncertainty. In addition to evaluating the risk of their behaviors to themselves and others, citizens also have to consider the most current regulation, which often varies federally and locally and by incidence numbers. Few tools help to stay informed about the current rules. The state-run German multi-hazard warning app NINA incorporated a feature for COVID-19, while two apps, DarfIchDas and CoroBuddy, focus only on COVID-19 regulation and are privately run. To investigate users’ expectations, perceived advantages, and gaps as well as the developers’ challenges, we analyze recent app store reviews of the apps and developers’ replies. We show that the warning app and the COVID-19 regulation apps are evaluated on different terms, that the correctness and portrayal of complex rules are the main challenges and that developers and editors are underusing users’ potential for crowdsourcing.
SYNC: A Crowdsourcing Platform for News Co-editing.	Jin-An Lin, Feng-Yi Hsu, Hsin-Yu Yao, Shang-Hsun Lu, Tsai-Yu Kuo, Chieh-Kai Lin, Yung-Ju Chang	cscw2021c	We present SYNC, a crowdsourcing platform that allows news audiences to read news curated, aggregated, organized, and edited by the crowd, and to participate in news aggregation and editing at anytime. Through crowdsourcing, SYNC brings together news information from diverse sources and from contributors with different perspectives, enabling news audiences to obtain a more complete context of specific news events, thereby synchronizing their knowledge of the event. SYNC employs ”blocks” and a timeline to help with editors structure and organize news information, and a news material panel to facilitate finding news material to help with aggregation and editing. Our user evaluation showed that participants were positive about the usefulness and societal impacts of SYNC, and found the user interface easy to follow. They also indicated improvements to make to better support news aggregation and editing.
"""Knock Knock, Here Is an Answer from Next Door"": Designing a Knowledge Sharing Chatbot to Connect Residents: Community Chatbot Design Case Study."	SangAh Park, Yoon Young Lee, Soobin Cho, Minjoon Kim, Joongseek Lee	cscw2021c	Our purpose is to investigate the potential use of chatbots for information sharing and social connection within a co-living space. To this end, we designed a chatbot for residents of a co-living space based on the following principles: (1) The range of shared information is limited to three areas derived from the similarities of the residents, and it takes a ‘give-and-take QnA’ structure, where one should answer a question from another resident after they ask a question. (2) Conversation is designed to resemble a human-like dialogue to reveal the presence of other residents. 19 residents of a co-living space used the chatbot for a week through the Wizard of Oz method, and six participants were asked about their chatbot experience through a semi-structured interview after the usage. A total of 58 interactions occurred, and the reply rate of the chatbot's question was 76%. The interview revealed that the users were satisfied with chatbot's provision of information that could only be given by fellow residents, and the chatbot increased the presence of other residents, creating a feeling of social connection. We conclude the paper by proposing design principles for chatbots in collective housing.
Investigating and Mitigating Biases in Crowdsourced Data.	Danula Hettiachchi, Mark Sanderson, Jorge Gonçalves, Simo Hosio, Gabriella Kazai, Matthew Lease, Mike Schaekermann, Emine Yilmaz	cscw2021c	It is common practice for machine learning systems to rely on crowdsourced label data for training and evaluation. It is also well-known that biases present in the label data can induce biases in the trained models. Biases may be introduced by the mechanisms used for deciding what data should/could be labelled or by the mechanisms employed to obtain the labels. Various approaches have been proposed to detect and correct biases once the label dataset has been constructed. However, proactively reducing biases during the data labelling phase and ensuring data fairness could be more economical compared to post-processing bias mitigation approaches. In this workshop, we aim to foster discussion on ongoing research around biases in crowdsourced data and to identify future research directions to detect, quantify and mitigate biases before, during and after the labelling process such that both task requesters and crowd workers can benefit. We will explore how specific crowdsourcing workflows, worker attributes, and work practices contribute to biases in the labelled data; how to quantify and mitigate biases as part of the labelling process; and how such mitigation approaches may impact workers and the crowdsourcing ecosystem. The outcome of the workshop will include a collaborative publication of a research agenda to improve or develop novel methods relating to crowdsourcing tools, processes and work practices to address biases in crowdsourced data. We also plan to run a Crowd Bias Challenge prior to the workshop, where participants will be asked to collect labels for a given dataset while minimising potential biases.
TickTalkTurk: Conversational Crowdsourcing Made Easy.	Sihang Qiu, Ujwal Gadiraju, Alessandro Bozzon	cscw2020c	This demo presents TickTalkTurk, a tool that can assist task requesters in quickly deploying crowdsourcing tasks in a customizable conversational worker interface. The conversational worker interface can convey task instructions, deploy microtasks, and gather worker input in a dialogue-based workflow. The interface is implemented as a Web-based application, which makes it compatible with popular crowdsourcing platforms. The tool we developed is demonstrated through two microtask crowdsourcing examples with different task types. Results reveal that our conversational worker interface is capable of better engaging workers and analyzing workers performance.
DREC: towards a Datasheet for Reporting Experiments in Crowdsourcing.	Jorge Ramírez, Marcos Báez, Fabio Casati, Luca Cernuzzi, Boualem Benatallah	cscw2020c	Factors such as instructions, payment schemes, platform demographics, along with strategies for mapping studies into crowdsourcing environments, play an important role in the reproducibility of results. However, inferring these details from scientific articles is often a challenging endeavor, calling for the development of proper reporting guidelines. This paper makes the first steps towards this goal, by describing an initial taxonomy of relevant attributes for crowdsourcing experiments, and providing a glimpse into the state of reporting by analyzing a sample of CSCW papers.
'Learning to code in a virtual world': A Preliminary Comparative Analysis of Discourse and Learning in Two Online Programming Communities.	Subhasree Sengupta	cscw2020c	Software programming is increasingly becoming a community-driven effort, with online discussion channels becoming vital resources for learning and knowledge sharing. This study explores differences in the discourse patterns of two popular online programming communities (Stack Overflow and r/Askprogramming) to provide preliminary insights into the type of learning practices these collectives support and scaffold. A three-step content analysis framework that investigates a sample of 8639 and 6126 contributions from Stack Overflow and r/Askprogramming respectively is presented. Preliminary results indicate that differences emerge in the scope of topics and the nature of responses the communities provide. While Stack Overflow is more task-specific, r/Askprogramming supports a greater sense of bonding and camaraderie among community members in addition to task-specific discussions. These results provide insights into the type of practices these communities support, which can be essential in considering how online communities that support learning activities should be designed.
Supporting Occasional Groups in Crowdsourcing Platforms.	Mahboobeh Harandi	cscw2019c	"Contributors to online crowdsourcing systems generally work independently on pieces of a product. Task interdependencies may require collaboration, mostly implicitly, to develop a final product. Even individuals engaged in a group conversation may not stay with the same group for long, i.e., the group is an ""occasional group"". Further, occasional group interactions are often not well supported by the platforms. These factors particularly impact the process of group learning. I plan to develop a model of group learning in occasional groups and to test the model by using it to design a knowledge-based chatbot to improve learning in occasional groups."
Solving Mysteries with the Wisdom of Crowds: A Modularized Pipeline and Context Slices.	Tianyi Li	cscw2019c	The increasing volume of text data is challenging the cognitive capabilities of experts. Machine learning and crowdsourcing present opportunities for large-scale distributed sensemaking, but we must overcome the challenge of modeling the holistic process so that many distributed agents can contribute to suitable components asynchronously and meaningfully. My dissertation work is devoted to addressing this challenge from a crowdsourcing perspective. Specifically, I study 1) how novice crowds can build theories from raw datasets without expert intervention; 2) what bottlenecks exist for crowds in the theory-building process; and 3) how previous crowd analyses can be refined to enable iterative crowdsourced sensemaking.
The Changing Landscape of Crowdsourcing in China: From Individual Crowdworkers to Crowdfarms.	Yihong Wang, Konstantinos Papangelis, Ioanna Lykourentzou, Vassilis-Javed Khan	cscw2019c	We report of a new crowdsourcing work paradigm that we came across while interviewing crowdworkers in China mid-May 2019 - that of companies that solely focus in undertaking and doing crowdsourcing tasks en masse. In addition, we discuss why such companies emerged recently, and how it affects the crowdsourcing landscape in China. With this work we highlight an important change in the rapidly changing crowdsourcing landscape of China that merits more research in the future.
Understanding How Social Prompts Influence Expert's Sharing of How-to Knowledge.	Chi-Lan Yang, Hao-Chuan Wang	cscw2019c	Numerous how-to tutorials and videos are pre-produced and archived for future learners' self-paced online learning. However, the co-presence of instructor and potential learners is missing when experts pre-produce how-to tutorials or videos offline. Hence, the content being shared by experts may not meet future learners' needs. To ensure the instructional value of archived tutorials for future learners, we explored ways to improve content production by analyzing interactive social prompts from a social partner during the time when experts share knowledge. We paired experts with partners of varying expertise and asked them to freely interact with the experts along the process. To simulate sharing knowledge via video-recording, a cooking task was deployed and we asked cooking experts to think-aloud while executing a cooking task with feedback from one of three types of paired partners, including another cooking expert, a novice, or no partner. This study identified six types of social prompts that can inform the design of computer-mediated knowledge sharing. Moreover, content quality was rated and evaluated, which shows that the best when knowledge was shared with the aid of expert's prompts. This study provides understanding of how various types of social prompts affect the externalization of how-to knowledge for asynchronous knowledge transfer between experts and future learners.
Service4Crowd: A Service Oriented Process Management Platform for Crowdsourcing.	Shujie Wu, Hailong Sun, Pengpeng Chen, Xudong Liu	cscw2018c	Crowdsourcing process management involves a complex workflow that needs to coordinate humans, machines and other resources. Most existing crowdsourcing platforms do not provide full-fledged process management, which affects the productivity of developing crowdsourcing applications and may also lead to low quality potentially. Although some tools have been designed for addressing the problem, most of them mainly target specific scenarios and are inflexible to be ex-tended. To overcome those limitations, we present Service4Crowd, a highly flexible and extensible process management platform for crowdsourcing that provides a one-stop solution for requesters based on service-oriented architecture. In Service4Crowd, a crowdsourcing process is implemented as a composite service, in which a component service represents an activity. We will demonstrate how these features facilitate the development, deployment and execution of a crowdsourcing application.
Tutorial Designs and Task Types in Zooniverse.	Holly Rosser, Andrea Wiggins	cscw2018c	Prior CSCW research has paid little attention to training for crowdsourcing project participants, which can require more than simple instructions. We examined the design of tutorials on the Zooniverse citizen science platform and identified aspects of tutorial design that aligned with task types, including more use of images and rich media for certain tasks. These findings support developing new tools for online tutorial creation, such as standard templates based on task characteristics.
Knowledge-Sharing Market: A Prediction Market-Based Knowledge-Sharing System.	Seiyu Yamaguchi, Hajime Mizuyama, Tomomi Nonaka, Mizuho Sato	cscw2018c	This paper proposes a new knowledge-sharing system that introduces an appropriate incentive for sharing valuable private knowledge and acquires high quality knowledge by using the gamification approach. This system is realized through an original extended prediction market mechanism with comment and knowledge-map functions. By utilizing the knowledge map created by connecting and evaluating comments gathered from participants, the proposed system could facilitate in fully utilizing knowledge in an organization. Specifically, by using the system, the owner of a mission can gather knowledge and skills required for succeeding the mission and (re)design the action plan for the mission collaboratively with the help of others.
Knowledge Sharing in Online Discussion Threads: What Predicts the Ratings?	Yuyang Liang	cscw2017	As an important category of user-generated content (UGC) community, Question and Answer (Q&A) community offers internet users opportunities to ask questions and share knowledge with others. In order to understand how the ratings of knowledge contribution quality correlate with the way knowledge is being shared in discussion threads, the study examines user behaviors and profiles in a large knowledge sharing community, /r/Techsupport, a discussion based Q&A site in Reddit.com concerning internet and technology problems. Negative binomial regressions and negative binomial mixed models are built to investigate the relationships among thread structure, level of user activity, user profiles and the ratings of threads and comments in the community. Results indicate that in the better rated threads, the structures tend to be more centralized with heterogeneous participants discussing the problem at a deeper level. Meanwhile, contributions with good ratings are more likely to be produced by users who are more engaged in commenting behaviors.
Mechanical Novel: Crowdsourcing Complex Work through Reflection and Revision.	Joy Kim, Sarah Sterman, Allegra Argent Beal Cohen, Michael S. Bernstein	cscw2017	Crowdsourcing systems accomplish large tasks with scale and speed by breaking work down into independent parts. However, many types of complex creative work, such as fiction writing, have remained out of reach for crowds because work is tightly interdependent: changing one part of a story may trigger changes to the overall plot and vice versa. Taking inspiration from how expert authors write, we propose a technique for achieving interdependent complex goals with crowds. With this technique, the crowd loops between reflection, to select a high-level goal, and revision, to decompose that goal into low-level, actionable tasks. We embody this approach in Mechanical Novel, a system that crowdsources short fiction stories on Amazon Mechanical Turk. In a field experiment, Mechanical Novel resulted in higher-quality stories than an iterative crowdsourcing workflow. Our findings suggest that orienting crowd work around high-level goals may enable workers to coordinate their effort to accomplish complex work.
A Glimpse Far into the Future: Understanding Long-term Crowd Worker Quality.	Kenji Hata, Ranjay Krishna, Li Fei-Fei, Michael S. Bernstein	cscw2017	Microtask crowdsourcing is increasingly critical to the creation of extremely large datasets. As a result, crowd workers spend weeks or months repeating the exact same tasks, making it necessary to understand their behavior over these long periods of time. We utilize three large, longitudinal datasets of nine million annotations collected from Amazon Mechanical Turk to examine claims that workers fatigue or satisfice over these long periods, producing lower quality work. We find that, contrary to these claims, workers are extremely stable in their quality over the entire period. To understand whether workers set their quality based on the task's requirements for acceptance, we then perform an experiment where we vary the required quality for a large crowdsourcing task. Workers did not adjust their quality based on the acceptance threshold: workers who were above the threshold continued working at their usual quality level, and workers below the threshold self-selected themselves out of the task. Capitalizing on this consistency, we demonstrate that it is possible to predict workers' long-term quality using just a glimpse of their quality on the first five tasks.
Collaboration Trumps Homophily in Urban Mobile Crowdsourcing.	Thivya Kandappu, Archan Misra, Randy Tandriansyah	cscw2017	"This paper establishes the power of dynamic collaborative task completion among workers for urban mobile crowd-sourcing. Collaboration is defined via the notion of peer referrals, whereby a worker who has accepted a location-specific task, but is unlikely to visit that location, offloads the task to a willing friend. Such a collaborative framework might be particularly useful for task bundles, especially for bundles that have higher geographic dispersion. The challenge, however, comes from the high similarity observed in the spatio-temporal pattern of task completion among friends. Using extensive real-world crowd-sourcing studies conducted over 7 weeks and 1000+ workers on a campus-based crowd-sourcing platform, we quantify the effect of such ""task completion homophily"", and show that incorporating such peer-preferences can improve worker-specific models of task preferences by over 30%. We then show that such collaborative offloading works in spite of such spatio-temporal similarity, primarily because workers refer tasks to their close friends, who in turn perform such peer-requested tasks (with over 95% completion rate) even if they experience detours that are significantly larger (often more than twice) than what they normally tolerate for platform-recommended tasks."
Designing for Targeted Responder Models: Exploring Barriers to Respond.	Kerem Özcan, Dawn Jorgenson, Christian Richard, Gary Hsieh	cscw2017	Targeted responder model is a recent approach in providing initial treatment to cardiac arrest patients. In this model, a group of trained responders are dispatched via mobile devices to nearby cardiac arrests. While prior work shows that targeted responder programs are successful in reducing average response time, less than a quarter of the responders who receive the notification of a nearby cardiac arrest travel to the scene of event. This study is an attempt to better understand barriers to respond in targeted responder programs. We conducted a weeklong diary study and focus groups with 12 participants. We identified four categories of barriers that emerge and we discussed the design implications of our findings within the broader context of location-based crowdsourcing.
Human Library: Understanding Experience Sharing for Community Knowledge Building.	Yun Huang, Brian Dobreski, Huichuan Xia	cscw2017	The human library is an event intended to engage members of the community in sharing and learning from each other's experiences, and is growing in popularity internationally. Human libraries fall within the larger scope of community knowledge sharing but have received little study and remain largely unsupported by technology. In this study, we examine how community libraries organize and host these events. We present how libraries have attempted to utilize technologies and leverage community support to enable human library events. Our findings reveal inconsistencies in the purpose of human library events, as well as technology applications that are not sufficient to support fully collaborative community knowledge building. We highlight opportunities for increased community participation and technological innovation and also suggest a broader consideration of computer-supported collaborative work in the context of human libraries and experience sharing.
Mass Participation During Emergency Response: Event-centric Crowdsourcing in Humanitarian Mapping.	Martin Dittus, Giovanni Quattrone, Licia Capra	cscw2017	Crowdsourcing platforms have become important information providers after disaster events. While they can build on some prior experiences, it is not yet well understood how contributor capacity for such activities is constituted. To what extent are initiatives building a dormant task force that springs to action when it is needed? Alternatively, do they mainly rely on the recruitment of new contributors during disaster events, possibly at the expense of contribution quality? We seek to develop a better understanding of these relationships, using the example of the Humanitarian OpenStreetMap Team. In a large-scale quantitative study, we assess the outcomes of 26 campaigns with almost 20,000 participants. We find that event-centric campaigns can be significant recruiting and reactivation events, however that this is not guaranteed. Our analytical methods provide a means of interpreting key differences in outcomes. We close with recommendations relating to the promotion and coordination of event-centric campaigns in HOT and related platforms.
Crowdsourcing as a Tool for Research: Implications of Uncertainty.	Edith Law, Krzysztof Z. Gajos, Andrea Wiggins, Mary L. Gray, Alex C. Williams	cscw2017	Numerous crowdsourcing platforms are now available to support research as well as commercial goals. However, crowdsourcing is not yet widely adopted by researchers for generating, processing or analyzing research data. This study develops a deeper understanding of the circumstances under which crowdsourcing is a useful, feasible or desirable tool for research, as well as the factors that may influence researchers' decisions around adopting crowdsourcing technology. We conducted semi-structured interviews with 18 researchers in diverse disciplines, spanning the humanities and sciences, to illuminate how research norms and practitioners' dispositions were related to uncertainties around research processes, data, knowledge, delegation and quality. The paper concludes with a discussion of the design implications for future crowdsourcing systems to support research.
Efficiently Identifying a Well-Performing Crowd Process for a Given Problem.	Patrick M. De Boer, Abraham Bernstein	cscw2017	With the increasing popularity of crowdsourcing and crowd computing, the question of how to select a well-performing crowd process for a problem at hand is growing ever more important. Prior work casted crowd process selection to an optimization problem, whose solution is the crowd process performing best for a user's problem. However, existing approaches require users to probabilistically model aspects of the problem, which may entail a substantial investment of time and may be error-prone. We propose to use black-box optimization instead, a family of techniques that do not require probabilistic modelling by the end user. Specifically, we adopt Bayesian Optimization to approximate the maximum of a utility function quantifying the user's (business-) objectives while minimizing search cost. Our approach is validated in a simulation and three real-world experiments. The black-box nature of our approach may enable us to reduce the entry barrier for efficiently building crowdsourcing solutions.
Kurator: Using The Crowd to Help Families With Personal Curation Tasks.	David Merritt, Jasmine Jones, Mark S. Ackerman, Walter S. Lasecki	cscw2017	People capture photos, audio recordings, video, and more on a daily basis, but organizing all these digital artifacts quickly becomes a daunting task. Automated solutions struggle to help us manage this data because they cannot understand its meaning. In this paper, we introduce Kurator, a hybrid intelligence system leveraging mixed-expertise crowds to help families curate their personal digital content. Kurator produces a refined set of content via a combination of automated systems able to scale to large data sets and human crowds able to understand the data. Our results with 5 families show that Kurator can reduce the amount of effort needed to find meaningful memories within a large collection. This work also suggests that crowdsourcing can be used effectively even in domains where personal preference is key to accurately solving the task.
Communicating Context to the Crowd for Complex Writing Tasks.	Niloufar Salehi, Jaime Teevan, Shamsi T. Iqbal, Ece Kamar	cscw2017	Crowd work is typically limited to simple, context-free tasks because they are easy to describe and understand. In contrast, complex tasks require communication between the requester and workers to achieve mutual understanding, which can be more work than it is worth. This paper explores the notion of structured communication: using structured microtasks to support communication in the domain of complex writing. Our studies compare a variety of communication mechanisms with respect to the costs to the requester in providing information and the value of that information to workers while performing the task. We find that different mechanisms are effective at different stages of writing. For early drafts, asking the requester to state the biggest problem in the current write-up is valuable and low cost, while later it is more useful for the worker if the requester highlights the text that needs to be improved. These findings can be used to enable richer, more interactive crowd work than what currently seems possible. We incorporate the findings in a workflow for crowdsourcing written content using appropriately timed mechanisms for communicating with the crowd.
Crowd Guilds: Worker-led Reputation and Feedback on Crowdsourcing Platforms.	Mark E. Whiting, Dilrukshi Gamage, Snehalkumar (Neil) S. Gaikwad, Aaron Gilbee, Shirish Goyal, Alipta Ballav, Dinesh Majeti, Nalin Chhibber, Angela Richmond-Fuller, Freddie Vargus, Tejas Seshadri Sarma, Varshine Chandrakanthan, Teógenes Moura, Mohamed Hashim Salih, Gabriel Bayomi Tinoco Kalejaiye, Adam Ginzberg, Catherine A. Mullings, Yoni Dayan, Kristy Milland, Henrique Orefice, Jeff Regino, Sayna Parsi, Kunz Mainali, Vibhor Sehgal, Sekandar Matin, Akshansh Sinha, Rajan Vaish, Michael S. Bernstein	cscw2017	Crowd workers are distributed and decentralized. While decentralization is designed to utilize independent judgment to promote high-quality results, it paradoxically undercuts behaviors and institutions that are critical to high-quality work. Reputation is one central example: crowdsourcing systems depend on reputation scores from decentralized workers and requesters, but these scores are notoriously inflated and uninformative. In this paper, we draw inspiration from historical worker guilds (e.g., in the silk trade) to design and implement crowd guilds: centralized groups of crowd workers who collectively certify each other's quality through double-blind peer assessment. A two-week field experiment compared crowd guilds to a traditional decentralized crowd work model. Crowd guilds produced reputation signals more strongly correlated with ground-truth worker quality than signals available on current crowd working platforms, and more accurate than in the traditional model.
Soylent Diet Self-Experimentation: Design Challenges in Extreme Citizen Science Projects.	Markéta Dolejsová, Denisa Kera	cscw2017	"Quantified self-experimentation with personal diets is a popular activity among health enthusiasts, diagnosed patients, as well as ""life hackers"" pursuing self-optimization goals. In this paper, we reflect on self-experimentation practices in the context of amateur citizen science communities. We report findings from 11 month-long qualitative fieldwork in a community of nutrition hobbyists experimenting with a powdered food substitute ""soylent"". Our respondents customized the soylent powders to their personal needs, tracked their metabolic reactions to the diet, and discussed their findings with the online soylent user community. Although the data and knowledge sharing within the community positively impacted respondents' nutrition literacy, these activities created risks regarding their health safety and data privacy. We define soylent self-experimentation as a form of ""extreme citizen science"". Based on the limitations identified in the soylent community, we suggest a set of design recommendations for extreme citizen science projects."
Designing Cooperative Gamification: Conceptualization and Prototypical Implementation.	Benedikt Morschheuser, Alexander Maedche, Dominic Walter	cscw2017	Organizations deploy gamification in CSCW systems to enhance motivation and behavioral outcomes of users. However, gamification approaches often cause competition between users, which might be inappropriate for working environments that seek cooperation. Drawing on the social interdependence theory, this paper provides a classification for gamification features and insights about the design of cooperative gamification. Using the example of an innova-tion community of a German engineering company, we present the design of a cooperative gamification approach and results from a first experimental evaluation. The findings indicate that the developed gamification approach has positive effects on perceived enjoyment and the intention towards knowledge sharing in the considered innovation community. Besides our conceptual contribu-tion, our findings suggest that cooperative gamification may be beneficial for cooperative working environments and represents a promising field for future research.
The Daemo Crowdsourcing Marketplace.	Snehalkumar (Neil) S. Gaikwad, Mark E. Whiting, Dilrukshi Gamage, Catherine A. Mullings, Dinesh Majeti, Shirish Goyal, Aaron Gilbee, Nalin Chhibber, Adam Ginzberg, Angela Richmond-Fuller, Sekandar Matin, Vibhor Sehgal, Tejas Seshadri Sarma, Ahmed Nasser, Alipta Ballav, Jeff Regino, Sharon Zhou, Kamila Mananova, Preethi Srinivas, Karolina R. Ziulkoski, Dinesh Dhakal, Alexander Stolzoff, Senadhipathige S. Niranga, Mohamed Hashim Salih, Akshansh Sinha, Rajan Vaish, Michael S. Bernstein	cscw2017c	The success of crowdsourcing markets is dependent on a strong foundation of trust between workers and requesters. In current marketplaces, workers and requesters are often unable to trust each other's quality, and their mental models of tasks are misaligned due to ambiguous instructions or confusing edge cases. This breakdown of trust typically arises from (1) flawed reputation systems which do not accurately reflect worker and requester quality, and from (2) poorly designed tasks. In this demo, we present how Boomerang and Prototype Tasks, the fundamental building blocks of the Daemo crowdsourcing marketplace, help restore trust between workers and requesters. Daemo's Boomerang reputation system incentivizes alignment between opinion and ratings by determining the likelihood that workers and requesters will work together in the future based on how they rate each other. Daemo's Prototype tasks require that new tasks go through a feedback iteration phase with a small number of workers so that requesters can revise their instructions and task designs before launch.
Collaborative Software Development Through Reflection and Storytelling.	Mark Mahoney	cscw2017c	Traditionally, it has been difficult for knowledge workers to share their experiences while working with computer based tools and technologies. This makes learning from experienced, well-informed peers a challenging endeavor. Storyteller is a tool for software developers that permits them to animate and annotate their previous programming sessions. Developers can record their thoughts, insights, and ideas as they relate to how their software evolved. They can use text, pictures, and audio to add contextual elements that are not possible in plain text files. The animated playbacks can be shared among developers on a team and promotes knowledge sharing, teaching, and learning.
Motivations for Participating in Online Initiatives: Exploring Contributory Behaviour Across Initiative Types.	Sarah Gilbert	cscw2017c	Online initiatives, a term that describes goal-oriented systems such as crowdsourcing, peer production, and online communities, are increasingly popular ways to source work from and harness the skills of distributed populations. The explosion of online initiatives in recent years has inspired scholarship examining why people contribute to these initiatives. While there is an abundance of case studies on motivation, there is a dearth of research that explores motivation between initiative types. Through case studies of two online initiatives, my dissertation research explores relationships between initiative structure, engagement, and participant role on motivation.
The Rise and Fall of Moral Labor in an Online Game Community.	Yubo Kou, Xinning Gui	cscw2017c	In this study we use moral labor to denote a particular form of work primarily driven by moral sense -- people believe it is right to do so and such work is utilized to improve commercial product. We examine moral labor in League of Legends, a popular online game. The game's developer, Riot Games, built a crowdsourcing platform that solicited free labor from players to deal with massive toxic behaviors including trolling, griefing, and bullying. Our ethnographic study of the game revealed how players willingly contributed their moral labor to improve the game regardless of rewards. We also found inherent tensions between players' moral sense and Riot's corporate agenda, manifested in the differences and similarities between the narrative of players and that from Riot, which evolved along the release, maintenance, and closure of the system. We consider future research directions on the relation of moral labor to online community.
Recruiting Messages Matter: Message Strategies to Attract Citizen Scientists.	Tae Kyoung Lee, Kevin Crowston, Carsten S. Østerlund, Grant Miller	cscw2017c	Although participation of citizen scientists is critical for a success of citizen science projects (a distinctive form of crowdsourcing), little attention has been paid to what types of messages can effectively recruit citizen scientists. Derived from previous studies on citizen scientists' motivations, we created and sent participants one of four recruiting messages for a new project, Gravity Spy, appealing to different motivations (i.e., learning about science, social proof, contribution to science, and altruism). Counter to earlier studies on motivation, our results showed that messages appealing to learning, contribution and social proof were more effective than a message appealing to altruism. We discuss the inconsistency between the present and prior study results and plans for future work.
I Know What You Coded Last Summer: Mining Candidate Expertise from GitHub Repositories.	Rohit Saxena, Niranjan Pedanekar	cscw2017c	Resumes and social recommendations are often high-level indicators of a candidate's technical skillset. In this paper, we present a method to create a more detailed technology skill profile of a candidate based on her code repository contributions. For this purpose, we annotate user contributions to GitHub code repositories with technology tags found in Stack Overflow questions and answers (Q&A) in an unsupervised manner. We also present SkillMap, a visual representation of candidate skill profile, for quick review and comparison with other candidate profiles. We create SkillMaps for 66 Java programmers and present a preliminary qualitative assessment though manual analysis and interviews of technical recruiters.
We Can Query More than We Can Tell: Facilitating Collaboration Through Query-Driven Knowledge-Sharing.	Andreas M. Wahl, Gregor Endler, Peter K. Schwab, Sebastian Herbst, Richard Lenz	cscw2017c	We introduce Query-driven Knowledge-Sharing Systems (QKSS), which extend data management systems with knowledge-sharing capabilities to facilitate collaboration among different teams of data scientists. Relevant tacit knowledge about data sources is extracted from SQL query logs and externalized to support data source discovery and data integration. By studying this collaborative knowledge, data scientists are enabled to formulate effective analytical queries over unfamiliar data sources.
Crowdsourcing Law and Policy: A Design-Thinking Approach to Crowd-Civic Systems.	Brian James McInnis, Alissa Centivany, Juho Kim, Marta Poblet, Karen Levy, Gilly Leshed	cscw2017c	Crowdsourcing technologies, strategies and methods offer new opportunities for bridging existing gaps among law, policymaking, and the lived experience of citizens. In recent years, a number of initiatives across the world have applied crowdsourcing to contexts including constitutional reform, drafting federal bills, and generating local policies. However, crowd-civic systems also come with challenges and risks such as socio-technical barriers, marginalization of specific groups, silencing of interests, etc. Using a design-thinking approach, this workshop will address both opportunities and challenges of crowd-civic systems to develop best practices for increasing public engagement with law and policy. The workshop organizers will suggest an initial framework explicitly intended to be criticized by participants and reconfigured through a series of iterative cooperative small-group activities focusing on ``diagnosing'' the failures of past crowd-civic system efforts and the successes of online action around social issues. While the ultimate objective of the workshop is to develop a best practices guide, we see iterations on the guide as a mechanism for fostering community and collaboration among policymakers, technologists, and researchers around crowd-civic systems for law and policy.
Analysing Volunteer Engagement in Humanitarian Mapping: Building Contributor Communities at Large Scale.	Martin Dittus, Giovanni Quattrone, Licia Capra	cscw2016	Organisers of large-scale crowdsourcing initiatives need to consider how to produce outcomes with their projects, but also how to build volunteer capacity. The initial project experience of contributors plays an important role in this, particularly when the contribution process requires some degree of expertise. We propose three analytical dimensions to assess first-time contributor engagement based on readily available public data: cohort analysis, task analysis, and observation of contributor performance. We apply these to a large-scale study of remote mapping activities coordinated by the Humanitarian OpenStreetMap Team, a global volunteer effort with thousands of contributors. Our study shows that different coordination practices can have a marked impact on contributor retention, and that complex task designs can be a deterrent for certain contributor groups. We close by providing recommendations about how to build and sustain volunteer capacity in these and comparable crowdsourcing systems.
The Crowd is a Collaborative Network.	Mary L. Gray, Siddharth Suri, Syed Shoaib Ali, Deepti Kulkarni	cscw2016	The main goal of this paper is to show that crowdworkers collaborate to fulfill technical and social needs left by the platform they work on. That is, crowdworkers are not the independent, autonomous workers they are often assumed to be, but instead work within a social network of other crowdworkers. Crowdworkers collaborate with members of their networks to 1) manage the administrative overhead associated with crowdwork, 2) find lucrative tasks and reputable employers and 3) recreate the social connections and support often associated with brick and mortar-work environments. Our evidence combines ethnography, interviews, survey data and larger scale data analysis from four crowdsourcing platforms, emphasizing the qualitative data from the Amazon Mechanical Turk (MTurk) platform and Microsoft's proprietary crowdsourcing platform, the Universal Human Relevance System (UHRS). This paper draws from an ongoing, longitudinal study of Crowdwork that uses a mixed methods approach to understand the cultural meaning, political implications, and ethical demands of crowdsourcing.
Personality Matters: Balancing for Personality Types Leads to Better Outcomes for Crowd Teams.	Ioanna Lykourentzou, Angeliki Antoniou, Yannick Naudet, Steven P. Dow	cscw2016	When personalities clash, teams operate less effectively. Personality differences affect face-to-face collaboration and may lower trust in virtual teams. For relatively short-lived assignments, like those of online crowdsourcing, personality matching could provide a simple, scalable strategy for effective team formation. However, it is not clear how (or if) personality differences affect teamwork in this novel context where the workforce is more transient and diverse. This study examines how personality compatibility in crowd teams affects performance and individual perceptions. Using the DISC personality test, we composed 14 five-person teams (N=70) with either a harmonious coverage of personalities (balanced) or a surplus of leader-type personalities (imbalanced). Results show that balancing for personality leads to significantly better performance on a collaborative task. Balanced teams exhibited less conflict and their members reported higher levels of satisfaction and acceptance. This work demonstrates a simple personality matching strategy for forming more effective teams in crowdsourcing contexts.
Toward Automatic Bootstrapping of Online Communities Using Decision-theoretic Optimization.	Shih-Wen Huang, Jonathan Bragg, Isaac Cowhey, Oren Etzioni, Daniel S. Weld	cscw2016	Successful online communities (e.g., Wikipedia, Yelp, and StackOverflow) can produce valuable content. However, many communities fail in their initial stages. Starting an online community is challenging because there is not enough content to attract a critical mass of active members. This paper examines methods for addressing this cold-start problem in datamining-bootstrappable communities by attracting non-members to contribute to the community. We make four contributions: 1) we characterize a set of communities that are “datamining-bootstrappable” and define the bootstrapping problem in terms of decision-theoretic optimization, 2) we estimate the model parameters in a case study involving the Open AI Resources website, 3) we demonstrate that non-members' predicted interest levels and request design are important features that can significantly affect the contribution rate, and 4) we ran a simulation experiment using data generated with the learned parameters and show that our decision-theoretic optimization algorithm can generate as much community utility when bootstrapping the community as our strongest baseline while issuing only 55% as many contribution requests.
Assignment Techniques for Crowdsourcing Sensitive Tasks.	L. Elisa Celis, Sai Praneeth Reddy, Ishaan Preet Singh, Shailesh Vaya	cscw2016	Protecting the privacy of crowd workers has been an important topic in crowdsourcing, however, task privacy has largely been ignored despite the fact that many tasks, e.g., form digitization, live audio transcription or image tagging often contain sensitive information. Although assigning an entire job to a worker may leak private information, jobs can often be split into small components that individually do not. We study the problem of distributing such tasks to workers with the goal of maximizing task privacy using such an approach. We introduce information loss functions to formally measure the amount of private information leaked as a function of the task assignment. We then design assignment mechanisms for three different assignment settings: PUSH, PULL and a new setting Tug Of War (TOW), which is an intermediate approach that balances flexibility for both workers and requesters. Our assignment algorithms have zero privacy loss for PUSH, and tight theoretical guarantees for PULL. For TOW, our assignment algorithm provably outperforms PULL; importantly the privacy loss is independent of the number of tasks, even when workers collude. We further analyze the performance and privacy tradeoffs empirically on simulated and real-world collusion networks and find that our algorithms outperform the theoretical guarantees.
Storia: Summarizing Social Media Content based on Narrative Theory using Crowdsourcing.	Joy O. Kim, Andrés Monroy-Hernández	cscw2016	People from all over the world use social media to share thoughts and opinions about events, and understanding what people say through these channels has been of increasing interest to researchers, journalists, and marketers alike. However, while automatically generated summaries enable people to consume large amounts of data efficiently, they do not provide the context needed for a viewer to fully understand an event. Narrative structure can provide templates for the order and manner in which this data is presented to create stories that are oriented around narrative elements rather than summaries made up of facts. In this paper, we use narrative theory as a framework for identifying the links between social media content. To do this, we designed crowdsourcing tasks to generate summaries of events based on commonly used narrative templates. In a controlled study, for certain types of events, people were more emotionally engaged with stories created with narrative structure and were also more likely to recommend them to others compared to summaries created without narrative structure.
Crowdsourcing Queue Estimations in Situ.	Jorge Gonçalves, Hannu Kukka, Iván Sánchez Milara, Vassilis Kostakos	cscw2016	We present the development and evaluation of a situated crowdsourcing mechanism that estimates queue length in real time. The system relies on public interactive kiosks to collect human estimations about their queue waiting time. The system has been designed as a standalone tool that can be retrospectively embedded in a variety of locations without interfacing with billing or customer systems. An initial study was conducted in order to determine whether people who just joined the queue would differ in their estimates from people who were at the front of the queue. We then present our system's evaluation in four different restaurants over 19 weekdays. Our analysis shows how our system is perceived by users, and we develop 2 ways to optimise the waiting time estimation: by correcting the estimations based on the position of the input mechanism, and by changing the sliding window considered inputs to provide better prediction. Our analysis shows that approximately 7% of restaurant customers provided estimations, but even so our system can provide predictions with up to 2 minute mean absolute error.
Distributed Analogical Idea Generation with Multiple Constraints.	Lixiu Yu, Robert E. Kraut, Aniket Kittur	cscw2016	Previous work has shown the promise of crowdsourcing analogical idea generation, where distributing the stages of analogical processing across many people can reduce fixation, identify inspirations from more diverse domains, and lead to more creative ideas. However, prior work has only considered problems with a single constraint, while many real-world problems involve multiple constraints. This paper contributes a systematic crowdsourcing approach for eliciting multiple constraints inherent in a problem and using those constraints to find inspirations useful in solving it. To do so we identify methods to elicit useful constraints at different levels of abstraction, and empirical results that identify how the level of abstraction influences creative idea generation. Our results show that crowds find the most useful inspirations when the problem domain is represented abstractly and constraints are represented more concretely.
ReLauncher: Crowdsourcing Micro-Tasks Runtime Controller.	Pavel Kucherbaev, Florian Daniel, Stefano Tranquillini, Maurizio Marchese	cscw2016	Task execution timeliness, i.e., the completion of a task within a given time frame, is a known open issue in crowdsourcing. While running tasks on crowdsourcing platforms a requester experiences long tails in execution caused by abandoned assignments (those left by workers unfinished), which become available for other workers only after some expiration time (e.g., 30 minutes in CrowdFlower). These abandoned assignments result in significant delays and a poor predictability of the overall task execution time. In this paper, we propose an approach and an implementation called ReLauncher to identify such abandoned assignments and relaunch them for other workers. We evaluate our implementation with an experiment on CrowdFlower that provides substantive evidence for a significant execution speed improvement with an average extra cost of about 10%.
Precision CrowdSourcing: Closing the Loop to Turn Information Consumers into Information Contributors.	Qian Zhao, Zihong Huang, F. Maxwell Harper, Loren G. Terveen, Joseph A. Konstan	cscw2016	We introduce a theoretical framework called precision crowdsourcing whose goal is to help turn online information consumers into information contributors. The framework looks at the timing and nature of the requests made of users and the feedback provided to users with the goal of increasing long-term contribution and engagement in the site or system. We present the results of a field experiment in which almost 3000 users were asked to tag movies (plus a null control group) as we varied the selection of task (popular/obscure), timing of requests (immediate or varying delays), and relational rhetoric (neutral, system reciprocal, other users reciprocal) of the requests. We found that asking increases tags provided overall, though asking generally decreases the provision of unprompted tags. Users were more likely to comply with our request when we asked them to tag obscure movies and when we used reciprocal request rhetoric.
Parting Crowds: Characterizing Divergent Interpretations in Crowdsourced Annotation Tasks.	Sanjay Kairam, Jeffrey Heer	cscw2016	"Crowdsourcing is a common strategy for collecting the “gold standard” labels required for many natural language applications. Crowdworkers differ in their responses for many reasons, but existing approaches often treat disagreements as ""noise"" to be removed through filtering or aggregation. In this paper, we introduce the workflow design pattern of crowd parting: separating workers based on shared patterns in responses to a crowdsourcing task. We illustrate this idea using an automated clustering-based method to identify divergent, but valid, worker interpretations in crowdsourced entity annotations collected over two distinct corpora -- Wikipedia articles and Tweets. We demonstrate how the intermediate-level view provide by crowd-parting analysis provides insight into sources of disagreement not easily gleaned from viewing either individual annotation sets or aggregated results. We discuss several concrete applications for how this approach could be applied directly to improving the quality and efficiency of crowdsourced annotation tasks."
Large-scale Volunteer Engagement in Humanitarian Mapping.	Martin Dittus	cscw2016c	Organisers of large crowdsourcing initiatives need to con-sider how to produce outcomes with their projects, but also how to build volunteer capacity. The initial contributor ex-perience plays an important role in this, particularly when contributions require some expertise: not all contributors who start to learn the practice are likely to be retained. My dissertation is focused on this growth challenge, using the example of the volunteer community of the Humanitarian OpenStreetMap Team. The research involves several quan-titative observational studies at the scale of the individual, the group, and the collective, and qualitative studies of con-tributor experiences.
Collective Creativity through a Micro-Tasks Crowdsourcing Approach.	Victor Girotto	cscw2016c	Research and commerce activity has been expanding the potential of micro-task markets. Initially used for simple, disconnected tasks, they have now been able to achieve impressive results in creative domains such as writing and design. The goals for this research are to further explore the possibilities of micro-task markets for performing creative work by defining a set of tasks and processes for such a synergistic creative collaboration, as well as expanding this micro-task approach beyond traditional markets such as Mechanical Turk to skilled and motivated communities.
Does the Sharing Economy do any Good?	Tawanna R. Dillahunt, Airi Lampinen, Jacki O'Neill, Loren G. Terveen, Cory Kendrick	cscw2016c	Despite the benefits offered by sharing economy, researchers have identified several challenges preventing disadvantaged groups (e.g. low socioeconomic status, un(der)employed and/or users from emerging regions) from receiving the same level of benefits as those from advantaged populations. This panel brings researchers from the sharing economy and mobile crowdsourcing space whose research has identified unique challenges for underserved populations. We consider the opportunities offered by these platforms to disadvantaged communities and examine to what extent these platforms instead may recreate disadvantage, as well as the workarounds communities employ to make these platforms work for them. We examine the opportunities for the CSCW community to address these challenges going forward.
MET: An Enterprise Market for Tasks.	Anupriya Ankolekar, Filippo E. Balestrieri, Sitaram Asur	cscw2016c	Crowdsourcing platforms have been rapidly harnessed by organizations for business uses, but enterprises continue to use traditional hierarchical forms of work allocation within their own boundaries. Using crowd work models within enterprises requires addressing enterprise-specific concerns such as how to maintain focus on employees' primary work while providing the right incentives to perform crowd work, how to promote wide employee participation while preserving management oversight and control. We present a novel crowd work system for the enterprise, the Market for Enterprise Tasks (MET), that addresses these concerns via two novel features: an incentive system tied to real-world dollars and multiple means of indirect control offered to the management, especially the ability to limit the size of tasks performed in the market. We have deployed MET in several groups within a large IT enterprise and report on initial experiences.
Towards a Framework for Collaborative Video Surveillance System Using Crowdsourcing.	Susumu Saito, Tetsunori Kobayashi, Teppei Nakano	cscw2016c	This paper proposes a new framework for video surveillance systems for crime prevention. The main purpose of this framework is to help provide reasonable and stable solutions for automated video surveillance systems in a collaborative way. This framework is characterized by a verification process using crowdsourcing after the image analysis process: automated image analyzer detects as many suspicious events as possible followed by filtering process using human intelligence, to achieve both high re-call and high precision rates. Here we describe the basic mechanisms for collaboration between camera devices, data stores, image analyzers and surveillance crowds.
Optil.io: Cloud Based Platform For Solving Optimization Problems Using Crowdsourcing Approach.	Szymon Wasik, Maciej Antczak, Jan Badura, Artur Laskowski, Tomasz Sternal	cscw2016c	The main objective of the presented research is to design a platform for continuous evaluation of optimization algorithms using crowdsourcing technique. The resulting platform, called Optil.io, runs in a cloud using platform as a service model and allows researchers from all over the world to collaboratively solve computational problems. This is the approach that has been already proved to be very successful for data mining problems by web services such as Kaggle. During our project we adapted this concept for solving computational problems that require implementation of software. To achieve this we designed the on-line judge system that receives algorithmic solutions in a form of source code from the crowd of programmers, compiles it, executes in a homogeneous run-time environment and objectively evaluates using the set of test cases. It was verified during internal experiments at the Poznan University of Technology and it is now ready to be presented to wider audience.
LBSNShield: Malicious Account Detection in Location-Based Social Networks.	Yuan Xuan, Yang Chen, Huiying Li, Pan Hui, Lei Shi	cscw2016c	Given the popularity of GPS-enabled smart devices, location-based social networks (LBSNs) have attracted numerous users around the world. The openness of LBSN platforms has also made themselves the targets of malicious attack-ers. In LBSNs, attackers can register a number of fake iden-tities and let them post spam reviews or fake check-ins. Therefore, discovering and blocking the malicious accounts are vital for the experience of legitimate users. In this pa-per, we investigated how to accurately detect malicious ac-counts in LBSNs. We collected rich user data from a pop-ular LBSN in China, so-called Dianping. We then built a crowdsourcing based annotation platform to mark legitimate and malicious accounts. By examining the annotated data set, we selected a number of key features to distinguish between these two types of accounts. Based on these fea-tures, we built LBSNShield, a machine learning-based mali-cious account detection system. According to our extensive evaluation, our system can achieve an F1-score of 0.89.
Authenticity, Relatability and Collaborative Approaches to Sharing Knowledge about Assistive Living Technology.	John Vines, Peter C. Wright, David Silver, Maggie Winchcombe, Patrick Olivier	cscw2015	Health and care providers are increasingly looking to online and peer-to-peer services to supplement existing channels of assistive living technology (ALTs) provision and assessment. We describe the findings from 12 co-design workshops with 28 people from the UK representing a range of older people with and without health conditions, users of ALT and carers for people using such devices. The workshops were conducted to explore issues related to finding reliable information about ALT with the goal of gathering requirements for the design of a peer-to-peer knowledge sharing platform. Our analysis highlights how a current reliance on peers and informal networks relates to a desire to establish the authenticity and relatability of another person's experience to one's own circumstances. This connects to a perceived mistrust in information where provenance and authenticity is not clear. We use these to critique the wisdom of taking an e-marketplace and recommendation service approach to ALT provision and assessment, and offer alternatives based on our findings.
Avoiding the South Side and the Suburbs: The Geography of Mobile Crowdsourcing Markets.	Jacob Thebault-Spieker, Loren G. Terveen, Brent J. Hecht	cscw2015	"Mobile crowdsourcing markets (e.g., Gigwalk and TaskRabbit) offer crowdworkers tasks situated in the physical world (e.g., checking street signs, running household errands). The geographic nature of these tasks distinguishes these markets from online crowdsourcing markets and raises new, fundamental questions. We carried out a controlled study in the Chicago metropolitan area aimed at addressing two key questions: (1) What geographic factors influence whether a crowdworker will be willing to do a task? (2) What geographic factors influence how much compensation a crowdworker will demand in order to do a task? Quantitative modeling shows that travel distance to the location of the task and the socioeconomic status (SES) of the task area are important factors. Qualitative analysis enriches our modeling, with workers mentioning safety and difficulties getting to a location as key considerations. Our results suggest that low-SES areas are currently less able to take advantage of the benefits of mobile crowdsourcing markets. We discuss the implications of our study for these markets, as well as for ""sharing economy"" phenomena like UberX, which have many properties in common with mobile crowdsourcing markets."
Social Eye Tracking: Gaze Recall with Online Crowds.	Shiwei Cheng, Zhiqiang Sun, Xiaojuan Ma, Jodi L. Forlizzi, Scott E. Hudson, Anind K. Dey	cscw2015	Eye tracking is a compelling tool for revealing people's spatial-temporal distribution of visual attention. But quality eye tracking hardware is expensive and can only be used with one person at a time. Further, webcam eye tracking systems have significant limitations on head movement and lighting conditions that result in significant data loss and inaccuracies. To address these drawbacks, we introduce a new approach that harnesses the crowd to understand allocation of visual attention. In our approach, crowdsourcing participants use mouse clicks to self-report the positions and trajectory for the following valuable eye tracking measures: first gaze, last gaze and all gazes. We validate our crowdsourcing approach with a user study, which demonstrated good accuracy when compared to a real eye tracker. We then deployed our prototype, GazeCrowd, in a crowdsourcing setting, and showed that it accurately generated gaze heatmaps and trajectory maps. Such an approach will allow designers to evaluate and refine their visual design without requiring the use of limited/expensive eye trackers.
Bridge the Gap!: What Can Work Design in Crowdwork Learn from Work Design Theories?	Obinna Anya	cscw2015	Integrating crowd-based systems to organizations is highly complex. A major of source of this complexity stems from the nature of organizational work design. Work design and configurations of work performance, in the traditional organizational model, are tightly woven into the structure and functions of organizations, whereas crowdwork leverages an undefined network of people without an organized managerial or hierarchical model. This paper examines work design theories in organizational studies with a view to exploring their potential for addressing the fundamental challenges of work design in organizational crowdwork. Drawing on review of extant literature on crowdwork and analysis of perspectives in work design theories, the paper outlines ways in which crowdsourcing research, on one hand, can interpret and utilize work design theories, and on the other, contribute to redesigning work design theories to keep pace with the important and rapid transformation of work from the traditional staffing paradigm to crowd and open models.
And Now for Something Completely Different: Improving Crowdsourcing Workflows with Micro-Diversions.	Peng Dai, Jeffrey M. Rzeszotarski, Praveen K. Paritosh, Ed H. Chi	cscw2015	"Crowdsourcing has become a popular and indispensable component of many problem-solving pipelines in the research literature, with crowd workers often treated as computational resources that can reliably solve problems that computers have trouble with, such as image labeling/classification, natural language processing, or document writing. Yet, obviously crowd workers are human, and long sequences of the same monotonous tasks might intuitively reduce the amount of good quality work done by the workers. Here we propose an investigation into how we can use diversions containing small amounts of entertainment to improve crowd workers' experiences. We call these small period of entertainment ``micro-diversions"", which we hypothesize to provide timely relief to workers during long sequences of micro-tasks. We hope to improve productivity by retaining workers to work on our tasks longer and to either improve or retain the quality of work. We experimentally test micro-diversions on Amazon's Mechanical Turk, a large paid-crowdsourcing platform. We find that micro-diversions can significantly improve worker retention rate while retaining the same work quality."
Exiting the Design Studio: Leveraging Online Participants for Early-Stage Design Feedback.	Xiaojuan Ma, Li Yu, Jodi L. Forlizzi, Steven P. Dow	cscw2015	Online collaboration tools enable developers of interactive systems to quickly reach potential users for usability testing. Can these technologies serve designers who seek feedback on user needs during the earliest stages of design? Online needfinding may help designers create products and services that can target a more diverse user population. To explore this, we conducted a feasibility study to compare face-to-face methods with online needfinding sessions. We found that video can sufficiently capture nuanced reactions to preliminary concept storyboards, but that feedback providers need guidance and structure. We then introduce a tool for collecting early-stage design feedback from online participants and conduct a case study with a professional design team. The team conducted needfinding activities with local participants, as well as a cost-equivalent number of online participants The case study demonstrates that combining online crowdsourcing with a video survey tool provides a simple and cost-efficient way to collect early-stage feedback.
The Effects of Visualizing Activity History on Attitudes and Behaviors in a Peer Production Context.	Jennifer Marlow, Laura A. Dabbish	cscw2015	In a variety of peer production settings, from Wikipedia to open source software development to crowdsourcing, individuals may encounter, edit, or review the work of unknown others. Typically this is done without much context to the person's past behavior or performance. To understand how exposure to an unknown individual's activity history influences attitudes and behaviors, we conducted an online experiment on Mechanical Turk varying the content, quality, and presentation of information about another Turker's work history. Surprisingly, negative work history did not lead to negative outcomes, but in contrast, a positive work history led to positive initial impressions that persisted in the face of contrary information. This work provides insight into the impact of activity history design factors on psychological and behavioral outcomes that can be of use in other related settings.
"Turkers, Scholars, ""Arafat"" and ""Peace"": Cultural Communities and Algorithmic Gold Standards."	"Shilad Sen, Margaret E. Giesel, Rebecca Gold, Benjamin Hillmann, Matt Lesicko, Samuel Naden, Jesse Russell, Zixiao ""Ken"" Wang, Brent J. Hecht"	cscw2015	"In just a few years, crowdsourcing markets like Mechanical Turk have become the dominant mechanism for for building ""gold standard"" datasets in areas of computer science ranging from natural language processing to audio transcription. The assumption behind this sea change - an assumption that is central to the approaches taken in hundreds of research projects - is that crowdsourced markets can accurately replicate the judgments of the general population for knowledge-oriented tasks. Focusing on the important domain of semantic relatedness algorithms and leveraging Clark's theory of common ground as a framework, we demonstrate that this assumption can be highly problematic. Using 7,921 semantic relatedness judgements from 72 scholars and 39 crowdworkers, we show that crowdworkers on Mechanical Turk produce significantly different semantic relatedness gold standard judgements than people from other communities. We also show that algorithms that perform well against Mechanical Turk gold standard datasets do significantly worse when evaluated against other communities' gold standards. Our results call into question the broad use of Mechanical Turk for the development of gold standard datasets and demonstrate the importance of understanding these datasets from a human-centered point-of-view. More generally, our findings problematize the notion that a universal gold standard dataset exists for all knowledge tasks."
Is It Good to Be Like Wikipedia?: Exploring the Trade-offs of Introducing Collaborative Editing Model to Q&A Sites.	Guo Li, Haiyi Zhu, Tun Lu, Xianghua Ding, Ning Gu	cscw2015	Online question and answer (Q&A) sites, which are platforms for users to post and answer questions on a wide range of topics, are becoming large repositories of valuable knowledge and important to societies. In order to sustain success, Q&A sites face the challenges of ensuring content quality and encouraging user contributions. This paper examines a particular design decision in Q&A sites-allowing Wikipedia-like collaborative editing on questions and answers, and explores its beneficial effects on content quality and potential detrimental effects on users' contributions. By examining five years' archival data of Stack Overflow, we found that the benefits of collaborative editing outweigh its risks. For example, each substantive edit from other users can increase the number of positive votes by 181% for the questions and 119% for the answers. On the other hand, each edit only decreases askers and answerers' subsequent contributions by no more than 5%. This work has implications for understanding and designing large-scale social computing systems.
Accessible Crowdwork?: Understanding the Value in and Challenge of Microtask Employment for People with Disabilities.	Kathryn Zyskowski, Meredith Ringel Morris, Jeffrey P. Bigham, Mary L. Gray, Shaun K. Kane	cscw2015	We present the first formal study of crowdworkers who have disabilities via in-depth open-ended interviews of 17 people (disabled crowdworkers and job coaches for people with disabilities) and a survey of 631 adults with disabilities. Our findings establish that people with a variety of disabilities currently participate in the crowd labor marketplace, despite challenges such as crowdsourcing workflow designs that inadvertently prohibit participation by, and may negatively affect the worker reputations of, people with disabilities. Despite such challenges, we find that crowdwork potentially offers different opportunities for people with disabilities relative to the normative office environment, such as job flexibility and lack of a need to rely on public transit. We close by identifying several ways in which crowd labor platform operators and/or individual task requestors could improve the accessibility of this increasingly important form of employment.
Motivating Multi-Generational Crowd Workers in Social-Purpose Work.	Masatomo Kobayashi, Shoma Arita, Toshinari Itoko, Shin Saito, Hironobu Takagi	cscw2015	Crowdsourcing for social goals (e.g., supporting public libraries or people with disabilities) is a promising area. However, little is known about how to develop active worker communities for such goals. First, we need reliable metrics for the workers' motivation. Second, the characteristics of senior crowd workers have rarely been studied, even though they often play a primary role in social-purpose work. This work introduces a four-quadrant worker motivation model for social-purpose crowdsourcing and describes a system based on that model. Then we investigate the outcomes from the system's operations for six months, which involved both young and senior workers, seeking better ways to build an active community of crowd workers. We analyzed the workers' activities based on the system logs, conducted a survey, assessed the correlations between the subjective values and actual behaviors, and then discuss the implications.
Games for Crowds: A Crowdsourcing Game Platform for the Enterprise.	Ido Guy, Anat Hashavit, Yaniv Corem	cscw2015	In this paper, we present a crowdsourcing game platform that allows users to play, create, and share simple games that harness the collective intelligence of employees within the enterprise. The platform uses the wizard design pattern to guide users through the process of creating a game. We describe the platform in detail and report our findings from deploying it within a large global organization for a period of three months, in which 34 games were created by 25 employees and played by 339. We combine qualitative and quantitative analysis to understand the characteristics of the different games and their impact on popularity and engagement, to validate our design goals, and to suggest potential enhancements.
Harnessing Twitter and Crowdsourcing to Augment Aurora Forecasting.	Nicolas J. LaLone, Andrea H. Tapia, Elizabeth MacDonald, Nathan A. Case, Michelle Hall, Jessica Clayton, Matthew J. Heavner	cscw2015c	The aurora borealis and aurora australis are beautiful space weather driven events whose sighting is typically based on luck given that forecasting is not spatially or temporally precise. To help increase the accuracy and timeliness of auroral forecasting, we have designed a multi-faceted system called Aurorasaurus. This system allows crisis management specialists to test reactions to rare event notifications, space weather scientists to get direct sighting information of auroras (complete with pictures), and science education researchers to evaluate the impact of educational materials about the aurora and the physics surrounding this unique phenomenon. Through manual tweet verification and directly reported aurora borealis or aurora australis sightings, everyday users help make space weather and aurora forecasting more accurate.
Method of Generating a Drawing by Crowdsourced Microtasks.	Kosuke Sasaki, Akira Hirata, Tomoo Inoue	cscw2015c	Illustrations, which attract readers and improve readability of documents, have high demand partly because not everybody can make them in good quality. Conventionally clients request professional creators to draw illustrations and pay rewards. However, there exists potential huge needs for less quality and less expensive illustrations. In this paper, we propose a new method of generating such drawings by crowdsourced microtasks. This paper also describes the Web-based crowdsourcing drawing system for the pilot study, in which various drawings could be successfully generated from the original photos.
Using TwitterTrails.com to Investigate Rumor Propagation.	Panagiotis Takis Metaxas, Samantha Finn, Eni Mustafaraj	cscw2015c	Social media have become part of modern news reporting, used by journalists to spread information and find sources, or as a news source by individuals. The quest for prominence and recognition on social media sites like Twitter can sometimes eclipse accuracy and lead to the spread of false information. As a way to study and react to this trend, we demo TWITTERTRAILS, an interactive, web-based tool (twittertrails.com) that allows users to investigate the origin and propagation characteristics of a rumor and its refutation, if any, on Twitter. Visualizations of burst activity, propagation timeline, retweet and co-retweeted networks help its users trace the spread of a story. Within minutes TWITTERTRAILS will collect relevant tweets and automatically answer several important questions regarding a rumor: its originator, burst characteristics, propagators and main actors according to the audience. In addition, it will compute and report the rumor's level of visibility and, as an example of the power of crowdsourcing, the audience's skepticism towards it which correlates with the rumor's credibility. We envision TWITTERTRAILS as valuable tool for individual use, and especially for amateur and professional journalists investigating recent and breaking stories.
Designing a Micro-Volunteering Platform for Situated Crowdsourcing.	Yi-Ching Huang	cscw2015c	Situated crowdsourcing has emerged to overcome the limitations of online and mobile crowdsourcing to allow people to perform a task by embedding an interface in a physical space. However, crowdsourcing for non-profits is a challenge in situated crowdsourcing platform. My dissertation investigates whether micro-volunteering can be applied successfully to a situated crowdsourcing platform for contributing problem-solving efforts with high-quality results.
Culture-aware Q&A Environments.	Nigini Abilio Oliveira	cscw2015c	This research project is a cross-culture study on social Q&A users' behavior. We search to understand variations on groups' contribution behavior to propose design alternatives that can promote intercultural collaboration. By studying large Q&A communities through social and anthropological lenses we plan to improve knowledge and techniques that can support designers and community managers to build better knowledge-sharing environments.
Can Gamification Motivate Voluntary Contributions?: The Case of StackOverflow Q&A Community.	Huseyin Cavusoglu, Zhuolun Li, Ke-Wei Huang	cscw2015c	Online communities heavily rely on voluntary participation and continued engagement from users because these sites can flourish only if there are meaningful contributions from community members. Gamifying the underlying incentive mechanism can be a solution to elicit and sustain the desired user behavior. In this paper, we develop a theory of gamification and study the impact of a hierarchical badges system, a reward mechanism based on gamification principles, on user participation and engagement at Stack Overflow Q&A site. Specifically, we assess the extent to which users are incentivized by earned badges in their contributions to the answering activity. Our initial results present strong empirical evidence that confirms the value of the badges and the effectiveness of gamification in stimulating voluntary participation.
Askalot: Community Question Answering as a Means for Knowledge Sharing in an Educational Organization.	Ivan Srba, Mária Bieliková	cscw2015c	Community Question Answering (CQA) is a well-known example of a knowledge management system for effective knowledge sharing in open online communities. In spite of the increasing research effort in recent years, the beneficial effects of CQA systems have not been fully discovered in organizational and educational environments yet. We present a novel concept of an organization-wide educational CQA system that fills the gap between open and too restricted class communities of learners. In order to evaluate its feasibility, we designed CQA system Askalot. Askalot was experimentally evaluated during a summer term at our university with more than 600 users. The results of the experiment provide an insight into employment of CQA systems as nontraditional learning environments that utilize a diversity of students' knowledge in a whole organization.
Connecting Collaborative & Crowd Work with Online Education.	Joseph Jay Williams, Markus Krause, Praveen K. Paritosh, Jacob Whitehill, Justin Reich, Juho Kim, Piotr Mitros, Neil T. Heffernan, Brian C. Keegan	cscw2015c	Human behavior increasingly involves digital online software, where the activities and resources that support (1) learning, (2) work, and (3) collaboration overlap and are placed in far greater proximity than the physical world -- often just a browser-tab or window away. What scientific and practical gains in 21st century learning, work, and collaboration can be achieved by integrating and contrasting these three areas' relevant technologies, scientific communities, and industry practitioners? For example: How can software for collaborative work incorporate learning? Which methods are effective for coordinating diverse experts to iteratively improve online educational resources? How can online learning improve the skill set and labor force for crowd work? What kinds of computational frameworks exist to jointly optimize the learning of skills and the use of these skills to achieve practical goals? This workshop tackles such questions by bringing together participants from industry (e.g., platforms similar to Odesk, Amazon Mechanical Turk); education, psychology, and MOOCs (e.g., attendees of AERA, EDM, AIED, Learning at Scale); crowdsourcing and collaborative work (e.g., attendees of CHI, CSCW, NIPS, AAAI's HCOMP).
Being a turker.	David B. Martin, Benjamin V. Hanrahan, Jacki O'Neill, Neha Gupta	cscw2014	Crowdsourcing is a key current topic in CSCW. We build upon findings of a few qualitative studies of crowdworkers. We conducted an ethnomethodological analysis of publicly available content on Turker Nation, a general forum for Amazon Mechanical Turk (AMT) users. Using forum data we provide novel depth and detail on how the Turker Nation members operate as economic actors, working out which Requesters and jobs are worthwhile to them. We show some of the key ways Turker Nation functions as a community and also look further into Turker-Requester relationships from the Turker perspective -- considering practical, emotional and moral aspects. Finally, following Star and Strauss [25] we analyse Turking as a form of invisible work. We do this to illustrate practical and ethical issues relating to working with Turkers and AMT, and to promote design directions to support Turkers and their relationships with Requesters.
The motivations and experiences of the on-demand mobile workforce.	Rannie Teodoro, Pinar Öztürk, Mor Naaman, Winter A. Mason, Janne Lindqvist	cscw2014	On-demand mobile workforce applications match physical world tasks and willing workers. These systems offer to help conserve resources, streamline courses of action, and increase market efficiency for micro- and mid-level tasks, from verifying the existence of a pothole to walking a neighbor's dog. This study reports on the motivations and experiences of individuals who regularly complete physical world tasks posted in on-demand mobile workforce marketplaces. Data collection included semi-structured interviews with members (workers) of two different services. The analysis revealed the main drivers for participating in an on-demand mobile workforce, including desires for monetary compensation and control over schedules and task selection. We also reveal main reasons for task selection, which involve situational factors, convenient physical locations, and task requester profile information. Finally, we discuss the key characteristics of the most worthwhile tasks and offer implications for novel crowdsourcing systems for physical world tasks.
How social Q&A sites are changing knowledge sharing in open source software communities.	Bogdan Vasilescu, Alexander Serebrenik, Premkumar T. Devanbu, Vladimir Filkov	cscw2014	Historically, mailing lists have been the preferred means for coordinating development and user support activities. With the emergence and popularity growth of social Q&A sites such as the StackExchange network (e.g., StackOverflow), this is beginning to change. Such sites offer different socio-technical incentives to their participants than mailing lists do, e.g., rich web environments to store and manage content collaboratively, or a place to showcase their knowledge and expertise more vividly to peers or potential recruiters. A key difference between StackExchange and mailing lists is gamification, i.e., StackExchange participants compete to obtain reputation points and badges. In this paper, we use a case study of R (a widely-used tool for data analysis) to investigate how mailing list participation has evolved since the launch of StackExchange. Our main contribution is the assembly of a joint data set from the two sources, in which participants in both the texttt{r-help} mailing list and StackExchange are identifiable. This permits their activities to be linked across the two resources and also over time. With this data set we found that user support activities show a strong shift away from texttt{r-help}. In particular, mailing list experts are migrating to StackExchange, where their behaviour is different. First, participants active both on texttt{r-help} and on StackExchange are more active than those who focus exclusively on only one of the two. Second, they provide faster answers on StackExchange than on texttt{r-help}, suggesting they are motivated by the emph{gamified} environment. To our knowledge, our study is the first to directly chart the changes in behaviour of specific contributors as they migrate into gamified environments, and has important implications for knowledge management in software engineering.
Remote shopping advice: enhancing in-store shopping with social technologies.	Meredith Ringel Morris, Kori Inkpen, Gina Venolia	cscw2014	"Consumers shopping in ""brick-and-mortar"" (non-virtual) stores often use their mobile phones to consult with others about potential purchases. Via a survey (n = 200), we detail current practices in seeking remote shopping advice. We then consider how emerging social platforms, such as social networking sites and crowd labor markets, could offer rich next-generation remote shopping advice experiences. We conducted a field experiment in which shoppers shared photographs of potential purchases via MMS, Facebook, and Mechanical Turk. Paid crowdsourcing, in particular, proved surprisingly useful and influential as a means of augmenting in-store shopping. Based on our findings, we offer design suggestions for next-generation remote shopping advice systems."
Aesthetic capital: what makes london look beautiful, quiet, and happy?	Daniele Quercia, Neil Keith O'Hare, Henriette Cramer	cscw2014	In the 1960s, Lynch's 'The Image of the City' explored what impression US city neighborhoods left on its inhabitants. The scale of urban perception studies until recently was considerably constrained by the limited number of study participants. We here present a crowdsourcing project that aims to investigate, at scale, which visual aspects of London neighborhoods make them appear beautiful, quiet, and/or happy. We collect votes from over 3.3K individuals and translate them into quantitative measures of urban perception. In so doing, we quantify each neighborhood's aesthetic capital. By then using state-of-the-art image processing techniques, we determine visual cues that may cause a street to be perceived as being beautiful, quiet, or happy. We identify effects of color, texture and visual words. For example, the amount of greenery is the most positively associated visual cue with each of three qualities; by contrast, broad streets, fortress-like buildings, and council houses tend to be associated with the opposite qualities (ugly, noisy, and unhappy).
A comparison of social, learning, and financial strategies on crowd engagement and output quality.	Lixiu Yu, Paul André, Aniket Kittur, Robert E. Kraut	cscw2014	A significant challenge for crowdsourcing has been increasing worker engagement and output quality. We explore the effects of social, learning, and financial strategies, and their combinations, on increasing worker retention across tasks and change in the quality of worker output. Through three experiments, we show that 1) using these strategies together increased workers' engagement and the quality of their work; 2) a social strategy was most effective for increasing engagement; 3) a learning strategy was most effective in improving quality. The findings of this paper provide strategies for harnessing the crowd to perform complex tasks, as well as insight into crowd workers' motivation.
Crowd synthesis: extracting categories and clusters from complex data.	Paul André, Aniket Kittur, Steven P. Dow	cscw2014	Analysts synthesize complex, qualitative data to uncover themes and concepts, but the process is time-consuming, cognitively taxing, and automated techniques show mixed success. Crowdsourcing could help this process through on-demand harnessing of flexible and powerful human cognition, but incurs other challenges including limited attention and expertise. Further, text data can be complex, high-dimensional, and ill-structured. We address two major challenges unsolved in prior crowd clustering work: scaffolding expertise for novice crowd workers, and creating consistent and accurate categories when each worker only sees a small portion of the data. To address these challenges we present an empirical study of a two-stage approach to enable crowds to create an accurate and useful overview of a dataset: A) we draw on cognitive theory to assess how re-representing data can shorten and focus the data on salient dimensions; and B) introduce an iterative clustering approach that provides workers a global overview of data. We demonstrate a classification-plus-context approach elicits the most accurate categories at the most useful level of abstraction.
Competing or aiming to be average?: normification as a means of engaging digital volunteers.	Chris Preist, Elaine Massung, David Coyle	cscw2014	Engagement, motivation and active contribution by digital volunteers are key requirements for crowdsourcing and citizen science projects. Many systems use competitive elements, for example point scoring and leaderboards, to achieve these ends. However, while competition may motivate some people, it can have a neutral or demotivating effect on others. In this paper we explore theories of personal and social norms and investigate normification as an alternative approach to engagement, to be used alongside or instead of competitive strategies. We provide a systematic review of existing crowdsourcing and citizen science literature and categorise the ways that theories of norms have been incorporated to date. We then present qualitative interview data from a pro-environmental crowdsourcing study, Close the Door, which reveals normalising attitudes in certain participants. We assess how this links with competitive behaviour and participant performance. Based on our findings and analysis of norm theories, we consider the implications for designers wishing to use normification as an engagement strategy in crowdsourcing and citizen science systems.
Reviewing versus doing: learning and performance in crowd assessment.	Haiyi Zhu, Steven P. Dow, Robert E. Kraut, Aniket Kittur	cscw2014	In modern crowdsourcing markets, requesters face the challenge of training and managing large transient workforces. Requesters can hire peer workers to review others' work, but the value may be marginal, especially if the reviewers lack requisite knowledge. Our research explores if and how workers learn and improve their performance in a task domain by serving as peer reviewers. Further, we investigate whether peer reviewing may be more effective in teams where the reviewers can reach consensus through discussion. An online between-subjects experiment compares the trade-offs of reviewing versus producing work using three different organization strategies: working individually, working as an interactive team, and aggregating individuals into nominal groups. The results show that workers who review others' work perform better on subsequent tasks than workers who just produce. We also find that interactive reviewer teams outperform individual reviewers on all quality measures. However, aggregating individual reviewers into nominal groups produces better quality assessments than interactive teams, except in task domains where discussion helps overcome individual misconceptions.
Next generation humanitarian computing.	Patrick Meier	cscw2014	deal with the rise of Big (Crisis) Data--the massive overflow of user-generated content posted on social media during disasters. To be sure, humanitarian organizations have no expertise in advanced computing. At the same time, the overflow of information during disasters can be as paralyzing to humanitarian response as the absence of information. This talk will highlight how the computing community can make a significant difference in humanitarian response. To demonstrate this, the talk will explain how we are experimenting with human and machine computing to make sense of--and verify--Big Crisis Data. For example, we can automatically extract crisis information from Twitter by combining microtasking with machine learning. This would enable UN information management officers to create their own classifiers on the fly. In terms of verification, we can draw on techniques from time-critical crowdsourcing to rapidly collect and triangulate evidence during disasters. This would allow emergency managers to quickly debunk rumors in the immediate aftermath of a crisis. In conclusion, the talk will outline how we can actively bridge the gap between humanitarian and computing communities.
USGS iCoast - did the coast change?: designing a crisis crowdsourcing App to validate coastal change models.	Sophia B. Liu, Barbara S. Poore, Richard J. Snell, Aubrey Goodman, Nathaniel G. Plant, Hilary F. Stockdon, Karen L. M. Morgan, M. Dennis Krohn	cscw2014c	"""iCoast -- Did the Coast Change?"" is a U.S. Geological Survey (USGS) research project that integrates crowdsourcing and citizen science techniques to develop a web application that allows interested volunteers to tag USGS oblique aerial photographs with qualitative information about the geomorphological changes to the coastline after Hurricane Sandy. iCoast has been collaboratively designed with coastal scientists to ensure that the crowdsourced data produced from iCoast can be used to help validate USGS predictive models of coastal change and to educate the public about coastal erosion after extreme storms. Different mechanisms for interacting with different crowds have been strategically implemented. Various sociotechnical challenges and unexpected outcomes have emerged."
CrowdCrit: crowdsourcing and aggregating visual design critique.	Kurt Luther, Amy Pavel, Wei Wu, Jari-Lee Tolentino, Maneesh Agrawala, Björn Hartmann, Steven P. Dow	cscw2014c	People who create visual designs often struggle to find high-quality critique outside a firm or classroom, and current online feedback solutions are limited. We created a system called CrowdCrit which leverages paid crowdsourcing to generate and visualize high-quality visual design critique. Our work extends prior crowd feedback research by focusing on scaffolding the process and language of studio critique for crowds.
Where the paddle meets the stream: bridging systems design theory and community-based monitoring practice.	S. Andrew Sheppard	cscw2014c	"My research is focused on computer support for community-based monitoring, at the intersection of citizen science, volunteered geographic information (VGI), and mobile crowdsourcing. Local-scale volunteer monitoring programs face a particular tension: the need to demonstrate the quality of the data they collect, while having limited resources available to provision and sustain ICT for data management and provenance tracking. As both a practitioner and an ethnographer, I am exploring ways to resolve this tension by documenting the challenges I observe and by proposing design recommendations where appropriate. My research to date is exemplified in ""wq"", which is both a set of design principles and a modular software framework I have built to address these challenges."
Software developers are humans, too!	Bogdan Vasilescu	cscw2014c	Open-source communities can be seen as knowledge-sharing ecosystems: participants learn from the community and from one another, and share their knowledge through contributions to the source code repositories or by offering support to users. With the emergence and growing popularity of social media sites targeting software developers (e.g., StackOverflow, GitHub), the paths through which knowledge flows within open-source software knowledge-sharing ecosystems are also beginning to change. My dissertation research seeks to raise our understanding of these changes.
NatureNet: a model for crowdsourcing the design of citizen science systems.	Mary Lou Maher, Jenny Preece, Tom Yeh, Carol L. Boston, Kazjon Grace, Abhijit Pasupuleti, Abigale Stangl	cscw2014c	NatureNet is citizen science system designed for collecting bio-diversity data in nature park settings. Park visitors are encouraged to participate in the design of the system in addition to collecting bio-diversity data. Our goal is to increase the motivation to participate in citizen science via crowdsourcing: the hypothesis is that when the crowd plays a role in the design and development of the system, they become stakeholders in the project and work to ensure its success. This paper presents a model for crowdsourcing design and citizen science data collection, and the results from early trials with users that illustrate the potential of this approach.
Crowdsourcing for grammatical error correction.	Ellie Pavlick, Rui Yan, Chris Callison-Burch	cscw2014c	We discuss the problem of grammatical error correction, which has gained attention for its usefulness both in the development of tools for learners of foreign languages and as a component of statistical machine translation systems. We believe the task of suggesting grammar and style corrections in writing is well suited to a crowdsourcing solution but is currently hindered by the difficulty of automatic quality control. In this proposal, we motivate the problem of grammatical error correction and outline the challenges of ensuring quality in a setting where traditional methods of aggregation (e.g. majority vote) fail to produce the desired results. We then propose a design for quality control and present preliminary results indicating the potential of crowd workers to provide a scalable solution.
Structures for knowledge co-creation between organisations and the public: (cop2014).	Laura Carletti, Tim Coughlan, Jon Christensen, Elizabeth Gerber, Gabriella Giannachi, Stefan Schutt, Rebecca Sinker, Carlos Denner dos Santos	cscw2014c	"In recent years, social computing technologies have emerged to support innovative new relationships between organisations and the public. Inspired by concepts such as collective intelligence, citizen science, citizen journalism and crowdsourcing, diverse types of organisations are aiming to increase engagement with the public, collect localised knowledge, or leverage human cognition and creativity. In supporting these approaches, organisations are often provoked to make their data and processes more open, and to be inclusive of differing motivations and perspectives from inside and outside the organisation. In doing so, they raise new questions for both designers and organisations. For example how are ""official"" and ""unofficial"" information sources combined or hosted, mediated, or considered reliable? Does the role of the professional change through greater involvement of amateurs? How are the motivations of members of the public harnessed for mutual benefit? This workshop brings together an interdisciplinary group of researchers to address those questions from different perspectives."
Back to the future of organizational work: crowdsourcing and digital work marketplaces.	Melissa Cefkin, Obinna Anya, Steve Dill, Robert Moore, Susan U. Stucky, Osarieme Omokaro	cscw2014c	Businesses increasingly accomplish work through innovative sourcing models that leverage the crowd. As a new way of distributing work across units within an organization and as a form of outsourcing work beyond organizational boundaries, crowdwork is inherently disruptive. Crowdwork raises a number of questions about its implications to the future of organizational work, including reconfigurations to the very nature of work, consideration of the opportunities and threats to both organizational forms and worker status, and about the systems that underlie and are meant to support crowdwork. There is a need for a clear research agenda to address these challenges and to inform the design of solutions for crowdwork as it integrates with other forms of organizational work.
The fourteenth international workshop on collaborative editing systems.	Michael S. MacFadden, Agustina, Ning Gu, Claudia-Lavinia Ignat, Haifeng Shen, David Sun, Chengzheng Sun	cscw2014c	Interest in collaborative editing (CE) has seen a dramatic rise in recent years. The ubiquity of cloud services, crowdsourcing, and mobile devices means that today's Internet citizens are increasingly accustomed to producing and editing data in a shared network environment. While systems such as Google Drive, Microsoft Web Apps, Apache Wave and Codoxware allow users to collaboratively edit shared information, they have just begun to scratch the surface of CE's full potential. In the coming years, users will expect to be able to collaboratively create, share, and edit documents and data in a dynamic, real-time, and intuitive manor. This workshop aims to connect researchers, developers, and users to help explore the future of CE in tomorrow's information landscape. This year's workshop focuses on how researchers and industry practitioners can work together to accelerate delivery of CE capabilities to meet the needs of the typical information-age user.
Quality control mechanisms for crowdsourcing: peer review, arbitration, & expertise at familysearch indexing.	Derek L. Hansen, Patrick John Schone, Douglas Corey, Matthew Reid, Jake Gehring	cscw2013	The FamilySearch Indexing project has enabled hundreds of thousands of volunteers to transcribe billions of records, making it one of the largest crowdsourcing initiatives in the world. Assuring high quality transcriptions (i.e., indexes) with a reasonable amount of volunteer effort is essential to keep pace with the mounds of newly digitized documents. Using historical data, we show the relationship between prior experience and native language on transcriber agreement. We then present a field experiment comparing the effectiveness (accuracy) and efficiency (time) of two quality control mechanisms: (1) Arbitration -- the existing mechanism wherein two volunteers independently transcribe records and disagreements go to an arbitrator, and (2) Peer Review -- a mechanism wherein one volunteer's work is reviewed by another volunteer. Peer Review is significantly more efficient, though not as effective for certain fields as Arbitration. Design suggestions for FamilySearch Indexing and related crowdsourcing initiatives are provided.
Complementarity of input devices to achieve knowledge sharing in meetings.	Himanshu Verma, Flaviu Roman, Silvia Magrelli, Patrick Jermann, Pierre Dillenbourg	cscw2013	In co-located meetings, participants create and share content to establish a common understanding. In this paper, we present a collaborative environment that enables group members to create and share content simultaneously by providing them with different kinds of individual input devices and a shared workspace. We also report on an exploratory study to investigate the influence of the input device used on the shared knowledge produced by the group. The results suggest that driven by the affordances, various input devices complement each other. We thus recommend groups to be equipped with multitude of them to support diverse meeting task demands. Additionally, we observed that groupware usage differs across various phases of the problem-solving activity. This provides implications for the design of collaborative environments to assist each of the respective phases of the task, in order to extend their usefulness for the group.
Contributor profiles, their dynamics, and their importance in five q&a sites.	Adabriand Furtado, Nazareno Andrade, Nigini Oliveira, Francisco Vilar Brasileiro	cscw2013	Q&A sites currently enable large numbers of contributors to collectively build valuable knowledge bases. Naturally, these sites are the product of contributors acting in different ways - creating questions, answers or comments and voting in these - contributing in diverse amounts, and creating content of varying quality. This paper advances present knowledge about Q&A sites using a multifaceted view of contributors that accounts for diversity of behavior, motivation and expertise to characterize their profiles in five sites. This characterization resulted in the definition of ten behavioral profiles that group users according to the quality and quantity of their contributions. Using these profiles, we find that the five sites have remarkably similar distributions of contributor profiles. We also conduct a longitudinal study of contributor profiles in one of the sites, identifying common profile transitions, and finding that although users change profiles with some frequency, the site composition is mostly stable over time.
Crowd vs. crowd: large-scale cooperative design through open team competition.	Cheong Ha Park, KyoungHee Son, Joon Hyub Lee, Seok-Hyung Bae	cscw2013	Following the recent remarkable successes of crowdsourcing, there have been attempts to apply it to design. However a design problem is often too complex and difficult to break down into simpler, distributable tasks as required by the conventional crowdsourcing model. In this paper, we present Crowd vs. Crowd (CvC), a novel design crowdsourcing method, where several design teams made up of designers and crowd compete with each other. In each team, a designer coordinates effective communication between the crowd members and takes responsibility for the final design output, and the crowd contributes at different stages of design. We conducted an initial evaluation of CvC in comparison with other collaborative design methods, and found that: CvC can attract more people to participate; the crowd can make useful contribution in CvC; CvC can produce competent design outputs. We then applied CvC to two real-life design problems: first, designing a new logo for a university department; second, for a small tech company. With quantitative and qualitative analyses on these applications, we observed that the elements of competition and collaboration helped to sustain the crowd's motivation to participate, and to produce quality design outcomes with higher level of satisfaction for the stakeholders.
EmailValet: managing email overload through private, accountable crowdsourcing.	Nicolas Kokkalis, Thomas Köhn, Carl Pfeiffer, Dima Chornyi, Michael S. Bernstein, Scott R. Klemmer	cscw2013	This paper introduces privacy and accountability techniques for crowd-powered systems. We focus on email task management: tasks are an implicit part of every inbox, but the overwhelming volume of incoming email can bury important requests. We present EmailValet, an email client that recruits remote assistants from an expert crowdsourcing marketplace. By annotating each email with its implicit tasks, EmailValet's assistants create a task list that is automatically populated from emails in the user's inbox. The system is an example of a valet approach to crowdsourcing, which aims for parsimony and transparency in access con-trol for the crowd. To maintain privacy, users specify rules that define a sliding-window subset of their inbox that they are willing to share with assistants. To support accountability, EmailValet displays the actions that the assistant has taken on each email. In a weeklong field study, participants completed twice as many of their email-based tasks when they had access to crowdsourced assistants, and they became increasingly comfortable sharing their inbox with assistants over time.
Leveraging partner's insights for distributed collaborative sensemaking.	Nitesh Goyal, Gilly Leshed, Susan R. Fussell	cscw2013c	SAVANT is a web-based tool that enables information and knowledge sharing between remote partners through explicit and implicit communication to help them collaboratively analyze and make sense of distributed data. SAVANT's implicit sharing provides an opportunity to leverage partners' insights and reduce cognitive tunneling, and explicit sharing facilitates discussion. Both techniques assist collaborative sensemaking processes.
Micro-volunteering: helping the helpers in development.	Michael S. Bernstein, Mike Bright, Ed Cutrell, Steven Dow, Elizabeth Gerber, Anupam Jain, Anand Kulkarni	cscw2013c	Finding and retaining volunteers is a challenge for most of the NGOs (non-government-organizations) or non-profit organizations worldwide. Quite often, volunteers have a desire to help but are hesitant in making time commitments due to busy lives or demanding schedules. Micro-volunteering or crowdsourced volunteering has taken off in the last few years where a task is divided into fragments and accomplished collectively by the crowd. Individuals are only required to work on small chunks of tasks during their bits of short free times during the day. This panel brings in an interesting mix of researchers from the crowdsourcing/development space and social entrepreneurs to discuss the pros and cons of micro-volunteering for non-profits and identify the missing blocks in enabling us to replicate this concept in developing regions worldwide.
Motivating crowds using social facilitation and social transparency.	Shih-Wen Huang, Wai-Tat Fu	cscw2013c	We reported results from an experiment using an image labeling task, when workers were able to compare their own labels with the labels generated by another worker, they were motivated to generate more labels. In addition, when the workers shared their demographic information with their colleagues, the number of labels generated by them became even higher. This indicates that we can utilize the power of social facilitation and social transparency to motivate workers in crowdsourcing to reduce operation costs and even enhance outcome quality.
CrowdCamp 2013: rapidly iterating crowd ideas.	Lydia B. Chilton, Paul André, Jeffrey P. Bigham, Mira Dontcheva, Elizabeth Gerber, Eric Gilbert	cscw2013c	The rapidly growing field of collective intelligence - encompassing crowdsourcing, human computation, and social computing - is having a tremendous impact on the way we work, live, and play. Building on the success of a CHI 2012 CrowdCamp, this two-day event focuses on developing ideas into concrete outputs: in-depth thoughts on hard problems, paper or coded prototypes, experiment design and data mining. We will bring together researchers and industry experts to discuss future visions and make tangible headway on those visions, as well as seeding collaboration. The outputs from discussion, brainstorming, and building will persist after the workshop for attendees and the community to view.
Participation in an online mathematics community: differentiating motivations to add.	Yla R. Tausczik, James W. Pennebaker	cscw2012c	Why do people contribute content to communities of question-answering, such as Yahoo! Answers? We investigated this issue on MathOverflow, a site dedicated to research-level mathematics, in which users ask and answer questions. MathOverflow is the first in a growing number of specialized Q&A sites using the Stack Exchange platform for scientific collaboration. In this study we combine responses to a survey with collected data on posting behavior on the site. User behavior suggests that building reputation is an important incentive, even though users do not report this in the survey. Level of expertise affects users' reported motivation to help others, but does not affect the importance of reputation building. We discuss the implications for the design of communities to target and encourage more contributions.
Barter: mechanism design for a market incented wisdom exchange.	Dawei Shen, Marshall W. van Alstyne, Andrew Lippman, Hind Benbya	cscw2012c	Information markets benefit the communities they serve by facilitating electronic distributed exchange and enhancing knowledge sharing, innovation, and productivity. This research explores innovative market mechanisms to build incentives while encouraging pro-social behavior. A key advantage of this study is a direct appeal to theories of information economics and macro policies to market design. We built and deployed a web-based software platform called Barter at several universities. Preliminary analysis of user data helps test information market effectiveness and illustrate effects of various market interventions. We present our design framework, demonstrate why such an architecture provides sustainable incentives, and list key findings learned in the process of system deployment.
A study of multilingual social tagging of art images: cultural bridges and diversity.	Irene Eleta, Jennifer Golbeck	cscw2012c	The goal of this study is to compare social tagging patterns in two languages in image collections of art, while seeking exploitable strengths for the application of multilingual social tagging in digital libraries and museums. Crowdsourcing the annotation of digital image collections of artworks to different language communities has the potential to bridge language borders and reach wider audiences. This mixed methods study is based on a collection of digital images of paintings for which tags in Spanish and English were collected. The results show that the level of agreement in the vocabulary describing an image does not change significantly when adding a second language, but different cultural perspectives can be found for certain images when comparing less frequent tags across languages. Understanding and comparing tagging behaviors across languages is necessary for the design of user interfaces that support diversity and encourage sharing of perspectives about the artwork images.
Collaboratively crowdsourcing workflows with turkomatic.	Anand Pramod Kulkarni, Matthew Can, Björn Hartmann	cscw2012c	Preparing complex jobs for crowdsourcing marketplaces requires careful attention to workflow design, the process of decomposing jobs into multiple tasks, which are solved by multiple workers. Can the crowd help design such workflows? This paper presents Turkomatic, a tool that recruits crowd workers to aid requesters in planning and solving complex jobs. While workers decompose and solve tasks, requesters can view the status of worker-designed workflows in real time; intervene to change tasks and solutions; and request new solutions to subtasks from the crowd. These features lower the threshold for crowd employers to request complex work. During two evaluations, we found that allowing the crowd to plan without requester supervision is partially successful, but that requester intervention during workflow planning and execution improves quality substantially. We argue that Turkomatic's collaborative approach can be more successful than the conventional workflow design process and discuss implications for the design of collaborative crowd planning systems.
Shepherding the crowd yields better work.	Steven Dow, Anand Pramod Kulkarni, Scott R. Klemmer, Björn Hartmann	cscw2012c	Micro-task platforms provide massively parallel, on-demand labor. However, it can be difficult to reliably achieve high-quality work because online workers may behave irresponsibly, misunderstand the task, or lack necessary skills. This paper investigates whether timely, task-specific feedback helps crowd workers learn, persevere, and produce better results. We investigate this question through Shepherd, a feedback system for crowdsourced work. In a between-subjects study with three conditions, crowd workers wrote consumer reviews for six products they own. Participants in the None condition received no immediate feedback, consistent with most current crowdsourcing practices. Participants in the Self-assessment condition judged their own work. Participants in the External assessment condition received expert feedback. Self-assessment alone yielded better overall work than the None condition and helped workers improve over time. External assessment also yielded these benefits. Participants who received external assessment also revised their work more. We conclude by discussing interaction and infrastructure approaches for integrating real-time assessment into online work.
Community-based web security: complementary roles of the serious and casual contributors.	Pern Hui Chia, John Chuang	cscw2012c	Does crowdsourcing work for web security? While the herculean task of evaluating hundreds of millions of websites can certainly benefit from the wisdom of crowds, skeptics question the coverage and reliability of inputs from ordinary users for assessing web security. We analyze the contribution patterns of serious and casual users in Web of Trust (WOT), a community-based system for website reputation and security. We find that the serious contributors are responsible for reporting and attending to a large percentage of bad sites, while a large fraction of attention on the goodness of sites come from the casual contributors. This complementarity enables WOT to provide warnings about malicious sites while differentiating the good sites from the unknowns. This in turn helps steer users away from the numerous bad sites created daily. We also find that serious contributors are more reliable in evaluating bad sites, but no better than casual contributors in evaluating good sites. We discuss design implications for WOT and for community-based systems more generally.
CrowdWeaver: visually managing complex crowd work.	Aniket Kittur, Susheel Khamkar, Paul André, Robert E. Kraut	cscw2012c	Though toolkits exist to create complex crowdsourced workflows, there is limited support for management of those workflows. Managing crowd workers and tasks requires significant iteration and experimentation on task instructions, rewards, and flows. We present CrowdWeaver, a system to visually manage complex crowd work. The system supports the creation and reuse of crowdsourcing and computational tasks into integrated task flows, manages the flow of data between tasks, and allows tracking and notification of task progress, with support for real-time modification. We describe the system and demonstrate its utility through case studies and user feedback.
Beyond data sharing: artifact ecology of a collaborative nanophotonics research centre.	Gerard Oleksik, Natasa Milic-Frayling, Rachel Jones	cscw2012c	Scientific communities have long been concerned with the design and implementation of effective infrastructures for data access and collaborative scientific work. Recent studies have shown an increase in collaborative data generation and reuse. However, further improvements require a deeper understanding of the social and technological circumstances under which they emerge. To that effect we conduct in-situ observation study of a Nano-photonics Research Centre. We consider the artifact ecology that evolved from the Centre's common experimentation and data platform, the scientific practices, and the intricate interactions with digital artifacts that arise from the researchers' activities. We uncover the use of progress summaries for collaborative data interpretation and knowledge sharing. By studying this reputable collaborative scientific environment we (1) identified the factors that led to its functional and effective artifact ecology and (2) propose expansions of tools and services to improve it further. The latter include effective support for contextual search, browsing, and flexible viewing of information artifacts based on relevant parameters and properties.
Collaborative workflow for crowdsourcing translation.	Vamshi Ambati, Stephan Vogel, Jaime G. Carbonell	cscw2012c	In this paper we explore the challenges in crowdsourcing the task of translation over the web in which remotely located translators work on providing translations independent of each other. We then propose a collaborative workflow for crowdsourcing translation to address some of these challenges. In our pipeline model, the translators are working in phases where output from earlier phases can be enhanced in the subsequent phases. We also highlight some of the novel contributions of the pipeline model like assistive translation and translation synthesis that can leverage monolingual and bilingual speakers alike. We evaluate our approach by eliciting translations for both a minority-to-majority language pair and a minority-to-minority language pair. We observe that in both scenarios, our workflow produces better quality translations in a cost-effective manner, when compared to the traditional crowdsourcing workflow.
Collective intelligence as community discourse and action.	Anna De Liddo, Simon Buckingham Shum, Gregorio Convertino, Ágnes Sándor, Mark Klein	cscw2012	Collective Intelligence (CI) research investigates the design of infrastructures to enable collectives to think and act intelligently, and intriguingly, more intelligently than individuals. Technologies such as idea management or argumentation tools, blogs, wikis, chats, forums, Q&A sites, and social networks provide unprecedented opportunities for entire communities or organizations to express a discourse and act at a massive scale. This workshop seeks to understand the forms of CI that can be constructed through discourse and action, which enables advanced forms of collective sensemaking such as idea generation and prioritization, argumentation, and deliberation. When does effective discourse help a collective outperform individuals? What functions should the next generation of social platforms support? How can we allow communities to efficiently manage many diverse ideas, argument, and deliberate? What patterns in discourse and action can be modeled computationally?
The future of collaborative software development.	Andrew Begel, James D. Herbsleb, Margaret-Anne D. Storey	cscw2012	Software development organizations are changing from traditional enterprise or open source teams to decentralized, inter-reliant, multi-scale ecosystems of software developers. This transformation presents novel challenges and opportunities to those seeking to understand, evaluate, support, and influence these organizations. The goals of this workshop are to bring together researchers who are interested in the evolution of software development organizations, highlighting the role of collaboration technology, such as crowdsourcing, social media, software hosting, and application marketplace services, in shaping organizational transformation, and coordinating future efforts.
MoCoMapps: mobile collaborative map-based applications.	Susanne Hupfer, Michael J. Muller, Stephen E. Levy, Daniel M. Gruen, Andrew Sempere, Steven I. Ross, Reid Priedhorsky	cscw2012	This video demonstrates an experiment in crowdsourcing both map-based data and also the applications that provide the maps, and also presents scenarios of use.
Modeling problem difficulty and expertise in stackoverflow.	Benjamin V. Hanrahan, Gregorio Convertino, Les Nelson	cscw2012	Supporting expert communities is becoming a 'must-have' capability whenever users are helping each other solve problems. Examples of these expert communities abound in the form of enthusiast communities, both inside and outside of organizations. In order to achieve success, these systems have to connect several different actors. In this paper we aim to inform the design of these Hybrid Intelligence Systems through the investigation of StackOverflow. Our focus in this paper is to develop indicators for hard problems and experts. The long-term goal of our study is to examine how complex problems are handled and dispatched across multiple experts. We outline implications for modeling these attributes and how they might inform better design in the future.
Social networking technologies and organizational knowledge sharing as a sociotechnical ecology.	Mohammad Hossein Jarrahi, Steve Sawyer	cscw2012	We focus on how the uses of social networking technologies (SNT) are bound up in knowledge sharing practices. For us SNT include weblogs, wikis, corporate social networking platforms, and social networking sites such as Facebook, Twitter, and LinkedIn. Our focus is to the uses of SNT relative to people's informal networks within and across organizations. We conceive these as multidimensional networks, treating technology and humans symmetrically and as members of the same sociotechnical ecology. To date, evidence indicates that SNTs have multiple roles regarding knowledge sharing in organizational contexts, and it appears that uses of SNT advance collaborative practices in ways not fully congruent with contemporary organizational practices.
Diversity within the crowd.	Durga M. Kandasamy, Kristal Curtis, Armando Fox, David A. Patterson	cscw2012	Though crowdsourcing holds great promise, many struggle with framing tasks and determining which members of the crowd should be recruited to obtain reliable output. In some cases, expert knowledge is desired but, given the time and cost constraints of the problem, may not be available. In this case, it would be beneficial to augment the expert input that is available with input from members of the general population. We believe that reduced reliance on experts will in some cases lead to acceptable performance while reducing cost and latency. In this work, we show that we are able to approach the performance of an expert group for an image labeling task, while reducing our reliance on experts by incorporating non-expert responses.
Minority voices of crowdsourcing: why we should pay attention to every member of the crowd.	Jennifer A. Noble	cscw2012	In this paper I look at the dynamics of human behavior in crowds, focusing the role of non-normative voices in current crowdsourcing initiatives. I reiterate the idea that the power of the crowd lies not in the majority but in the collective. Many popular crowdsourcing platforms are designed to disregard outliers and only reward answers that agree with the masses. I use the example of the Long Tail in order to challenge developers to design more crowdsourcing tasks that take advantage of wide variance.
Social networking technologies and knowledge sharing in organizations.	Mohammad Hossein Jarrahi	cscw2012	My doctoral research is an exploratory project focused on understanding and theorizing on the ways in which various social networking technologies (SNTs) facilitate informal knowledge sharing in the workplace. Forms of SNT include (but are not limited to) corporate social networking platforms, weblogs, wikis, and social networking sites such as Facebook, Twitter and LinkedIn. Here I discuss the work to date, outline future steps and detail the expected contributions of this research. The primary outcome of this research is a greater conceptualization of the role and value of various SNTs for knowledge sharing in organizational contexts, which still remain understudied within the CSCW arena.
Look ma, no email!: blogs and IRC as primary and preferred communication tools in a distributed firm.	Aditya Johri	cscw2011	Email has been the primary communication medium in organizations for decades and despite studies that demonstrate its obvious disadvantages, the prevailing thinking is that email is irreplaceable. In this paper I challenge that view through a field study of a distributed firm that is highly successful in developing and delivering products without regular use of email in the workplace. Group blogging and IRC were the primary tools used and they allowed improved coordination and knowledge sharing compared to email. This paper contributes to scant literature in CSCW on firm-level technology use.
